---
title: "old_workflow"
description: "Full pipeline for RNA002 data (old chemistry)"
categories: [bash, pipeline, rna002]
---

# Pipeline for analysis of the Old Chemistry (RNA002) 
full start to finish workflow for basecalling and minimapping for rna002 data
*designed for OSCER supercomputer, ignore batch script/slurm parts for local/others*

## Beginning batch script to run on slurm 

```
    #!/bin/bash
    #SBATCH --partition=rnafold                       #where it runs (use "rnafold" or "normal")
    #SBATCH --job-name=12samples_dorado                     #name your job 
    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename
    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name
    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do "gpus-per-node=1" 
    #SBATCH --time=24:00:00          #this just sets to 1 day  
    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs
```
I've installed all the software you will need so just copy and paste the path I provide as given and it'll work (lmk if its prevented by permissions or anything)

**The first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can't write "U" so every call will say "T" instead but it means uracil.**

For any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I've spent hours before looking at why my code wont run to find out this is why

The following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX).
Just copy paste this chunk after the sbatch part but before the dorado script.

```
        module load GCC
        module load PyTorch
        module load FlexiBLAS/3.3.1-GCC-12.3.0  
        module load FFmpeg/4.4.2-GCCcore-11.3.0 
        module load HTSlib
        module load protobuf

        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too
```


To run dorado youll follow this formatting 
for reference, adding "\\" to the end of the line tells your system that the command isn't done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.


#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.

```
        "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado" \ 
        basecaller \ 
        "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/" \
        --min-qscore 10 \
        --emit-fastq > "/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq"  
```

*if you ever chose to do modifications then u have to remove the "--emit-fastq" tag and change the output to be a ".bam", as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.*
        
I prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the ">" as it says redirect this entire command into this output.
        
A qscore of 10 only keeps calls >=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.


**The next step is minimap2, where you take the fastq output and align it to your reference. I'll attach the path for the human transcriptome/genome, but I don't have the viral reference.**
    
```
                        "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2" \
        -ax splice -uf -k14 -y --secondary=no \     #keep these settings. its importnat
        "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa" \ #this is your ref file (MUST BE .fasta or .fa) 
        "/this/is/your/dorado/output/that/your/mapping.fastq" > "               "/this/is/your/output/alignedsplice.sam    
```

*If you would rather use the transcriptome I'll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it*
**path : "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa"**

The output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant). 

Next step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).

**output goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters.
output must be .bam and input is the .sam**

```
        samtools sort -o "/THIS/IS/OUTPUT/FIRST/SORTED.BAM" "/This/is/input/alignedsplice.sam" 

        samtools flagstat  "/THIS/IS/OUTPUT/FIRST/SORTED.BAM"  
```

**Flagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you'll need comparing the viral reference to using genome or transcriptome.**





# Counting Transcript Abundance and Plotting Differential Expression Volcano Plots

**Now for the really complicated part**

after aligning to the reference, the goal is to count how many copies of each gene is expressed in each sample. This will be done using salmon, which can be installed directly into a conda environment for you (I'll add the exact code to run for this below too)

```
        # Install Salmon in a conda environment
        conda create -n salmon_env -c bioconda salmon
        conda activate salmon_env
```

So this part can be done on the login node, and add this little chunk of code to your data file, under the #SBATCH part but above your code.

```    
        echo "linking the Conda environment to $ENV_PATH..."
        source /opt/oscer/software/Mamba/23.1.0-4/etc/profile.d/conda.sh
        conda activate salmon_env
```

Now for the salmon command itself to quantify. It's important that the transcriptome is used here as reference because it needs to be able to count isoforms. (the genome has higher accuracy in minimap step than transcript but that shouldn't change results for this software)

Salmon likes to put all results into a directory, and then the next step pulls directly from it, so run this command but change to whatever directory your using. End the file name with the sample name you're running salmon on and don't add a "/" to the very end, this way the output will separate by sample and work much better for later steps.

```
        #mkdir -p "/ourdisk/hpc/rnafold/UR_USER/dont_archive/salmon/BYSAMPLE"
```

**The following code you shouldn't need to run if you use my reference transcript file, but for the viral genome (if that ends up being used here) you'll use this.**

```
        salmon index -t "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa" -i "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts_index" -k 31 
```

I believe the part after "-i" is saying where the script can write all the little files it creates to index the reference.

**this is the important step**

```
        salmon quant -t "/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa" -l A -a
        "/input/ALIGNED/SORTED/data.bam" -p 8 --seqBias --gcBias -o "/this/is/output/directory/by/sample/"
```

Online documentation had stuff on --seqBias and --gcBias so included, but I'm not 100% sure if they're necessary

Now for running R on OSCER, just write a normal unix script, and add "Rscript (file)" in that unix script. I've heard of people shutting down nodes from running python or R directly on the command line so I would recommend against.

**No clue why but its very difficult to get the R packages working on OSCER, I use alot of ChatGPT when trying to do this and I believe there should be some modules already on oscer that have necessary packages (try module avail R).** 


## This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I've commented.
   
    
```
    library(txdbmaker)
    library(GenomicFeatures)
    
#*GTF file with annotated transcripts/regions*
  
    txdb <- makeTxDbFromGFF("gencode.v47.annotation.gtf")

    k <- keys(txdb, keytype = "TXNAME")  # make sure keytype exists
    tx2gene <- AnnotationDbi::select(txdb, keys = k, columns = "GENEID", keytype = "TXNAME")
``` 

**metadata is just sample and condition listed in "\t" format"**

```
    library(tidyverse)
    metadata <- read_delim("metadata.txt", delim = "\t", 
                       escape_double = FALSE, trim_ws = TRUE)


    setwd("C:/Users/gjand/Downloads/Schroeder_Lab/data/salmonm6a")
    files <- paste(metadata$run, "/quant.sf", sep = "")
    library(tximport)
    txi <- tximport(files, type = "salmon", tx2gene = tx2gene, txOut = F, ignoreAfterBar = T)

    txi$counts |> head()



    library(DESeq2)
    metadata$individual <- as.factor(metadata$individual)

    #  prepare deseq object
    dds <- DESeqDataSetFromTximport(txi = txi, colData = metadata, 
                                design = ~individual + condition)

    dds <- DESeq(dds, parallel = T)


    # non batch corrected PCA
    vsd <- rlog(dds, blind = F)
    pca_data <- plotPCA(vsd, intgroup = c("condition", "individual"), returnData = TRUE)
    percentVar <- round(100 * attr(pca_data, "percentVar"))
    library(cowplot)
    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +
      geom_point(size = 3) +
      xlab(paste0("PC1: ", percentVar[1], "% variance")) +
      ylab(paste0("PC2: ", percentVar[2], "% variance")) +
      ggtitle("Principal Component Analysis") +
     # scale_color_manual(values = c("black", "gray65", "darkblue", "cadetblue3", "springgreen4", "springgreen2")) +
      theme(aspect.ratio = 1) +
      theme_cowplot(24) 
    # stat_ellipse(aes(group = Condition), type = "t", level = 0.65)

    # ggsave(plot = last_plot(),
    #        "/name/of/save/output/path.png",
    #        width = 12, height = 9, units = "in", dpi =300, bg = "white")
```

    ########################
**PCA to measure correlation between samples (need to remove batch-effect from individuals so that condition is the main difference)**

```  
        # Batch corrected PCA
    vsd <- rlog(dds, blind = F)
    assay(vsd) <- limma::removeBatchEffect(assay(vsd), vsd$individual)
    pca_data <- plotPCA(vsd, intgroup = c("condition", "individual"), returnData = TRUE)
    percentVar <- round(100 * attr(pca_data, "percentVar"))

    # Custom PCA plot
    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +
      geom_point(size = 6) +
      xlab(paste0("PC1: ", percentVar[1], "% variance")) +
      ylab(paste0("PC2: ", percentVar[2], "% variance")) +
      ggtitle("Principal Component Analysis") +
      theme(aspect.ratio = 1) +
      theme_cowplot(24) +
      stat_ellipse(type = "t", level = 0.95)

    # ggsave(plot = last_plot(),
    #        "/name/of/save/output/path.png",
    #        width = 12, height = 9, units = "in", dpi =300, bg = "white")

    library(org.Hs.eg.db)

    mapping <- AnnotationDbi::select(org.Hs.eg.db, keys = keys(org.Hs.eg.db),
                                 columns = c("GENENAME", "ENSEMBL", "SYMBOL", "REFSEQ"))


    library(biomaRt)
    mart <- useMart("ensembl", dataset="hsapiens_gene_ensembl")

    # biomaRt can sometimes handle versioned IDs directly
    listAttributes(mart) ->atts

    mapping <- getBM(attributes=c("ensembl_gene_id", "ensembl_gene_id_version", "external_gene_name",
                              "description"),
                 filters="ensembl_gene_id_version",
               values=tx2gene$GENEID,
                 mart=mart)



    # get differential eaxpression results data frame
    res_df <- results(dds, contrast = c("condition", "smoke", "ctrl"), tidy = T)

    res_df_ann <- res_df %>%
      left_join(., mapping, by = c("row" = "ensembl_gene_id_version"))


    library(EnhancedVolcano)
    EnhancedVolcano(res_df_ann,
                lab = res_df_ann$external_gene_name,
                x = 'log2FoldChange',
                y = 'padj',
                pointSize = 2
                )
    # 

        cat("All steps completed.\n")
```



