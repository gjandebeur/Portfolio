[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gjandebeur’s Github",
    "section": "",
    "text": "Current PhD Student at OUHSC interested in computational biology and bioinformatics"
  },
  {
    "objectID": "scripts.html",
    "href": "scripts.html",
    "title": "Scripts",
    "section": "",
    "text": "Collection of scripts I’ve written:\n\n\nOld Workflow\nPreprocessing on RNA002 (old) chemistry data using UNIX\nView\n\n\nModkit Analysis\nR script for modkit analysis pipeline\nView\n\n\nGenome Assembly\nBash script to assemble genome both De Novo & Reference-Based\nView\n\n\nSubstitution Plot Bash & R scripts to produce accuracy of basecaller plot\nView Unix Script | View R Script\n\n\nModkit Installation Using singularity/apptainer to install modkit  onto OSCER for up-to-date analyses View\n\n\nHelpful R Scripts for Analysis Downstream analysis options from  pA, exon length, stoich, and etc View polyA Length | View motif analysis | View Exon Length | View Stoichiometry | View GO Analysis\n\n\nDifferential Expression and Modification Script to perform Differential Expression, Modification, and PCA plot View"
  },
  {
    "objectID": "scripts/differential_analyses.html",
    "href": "scripts/differential_analyses.html",
    "title": "differential_analyses",
    "section": "",
    "text": "Differential Expression and Modification Script\nlibrary(txdbmaker) library(GenomicFeatures)\ntxdb &lt;- makeTxDbFromGFF(“reference.gtf”)\nk &lt;- keys(txdb, keytype = “TXNAME”) # make sure keytype exists tx2gene &lt;- AnnotationDbi::select(txdb, keys = k, columns = “GENEID”, keytype = “TXNAME”)\nlibrary(tidyverse) metadata &lt;- read_delim(“path/to/metadata.txt”, delim = “,”, escape_double = FALSE, trim_ws = TRUE)\n#setwd(“salmondata”) files &lt;- paste0(metadata\\(sample, \"/quant.sf\")\nnames(files) &lt;- metadata\\)sample\n\n\nVerify files exist\nfile.exists(files)\nlibrary(tximport) txi &lt;- tximport(files, type = “salmon”, tx2gene = tx2gene, txOut = F, ignoreAfterBar = T)\ntxi$counts |&gt; head()\nlibrary(DESeq2) metadata\\(individual &lt;- as.factor(metadata\\)individual)\n\n\nprepare deseq object\ndds &lt;- DESeqDataSetFromTximport(txi = txi, colData = metadata, design = ~individual + condition)\ndds &lt;- DESeq(dds, parallel = T)\n\n\nnon batch corrected PCA\nvsd &lt;- rlog(dds, blind = F) pca_data &lt;- plotPCA(vsd, intgroup = c(“condition”, “individual”), returnData = TRUE) percentVar &lt;- round(100 * attr(pca_data, “percentVar”)) library(cowplot) ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) + geom_point(size = 3) + xlab(paste0(“PC1:”, percentVar[1], “% variance”)) + ylab(paste0(“PC2:”, percentVar[2], “% variance”)) + ggtitle(“Principal Component Analysis”) + # scale_color_manual(values = c(“black”, “gray65”, “darkblue”, “cadetblue3”, “springgreen4”, “springgreen2”)) + theme(aspect.ratio = 1) + theme_cowplot(24) # stat_ellipse(aes(group = Condition), type = “t”, level = 0.65)\n\n\nggsave(plot = last_plot(),\n\n\n“save/here.png”,\n\n\nwidth = 12, height = 9, units = “in”, dpi =300, bg = “white”)\n\n\nBatch corrected PCA creation\nvsd &lt;- rlog(dds, blind = F) assay(vsd) &lt;- limma::removeBatchEffect(assay(vsd), vsd$individual) pca_data &lt;- plotPCA(vsd, intgroup = c(“condition”, “sample”), returnData = TRUE) percentVar &lt;- round(100 * attr(pca_data, “percentVar”))\n\n\nCustom PCA plot\nggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = sample)) + geom_point(size = 6) + xlab(paste0(“PC1:”, percentVar[1], “% variance”)) + ylab(paste0(“PC2:”, percentVar[2], “% variance”)) + ggtitle(“Principal Component Analysis”) + theme(aspect.ratio = 1) + theme_cowplot(24) + stat_ellipse(type = “t”, level = 0.95)\n#ggsave(plot = last_plot(), # “save/here.png”, # width = 12, height = 9, units = “in”, dpi =300, bg = “white”) # # )\n\n\nCreation of Differential Expression Volcano Plot\n\n\ngene id symbol mapping\nlibrary(org.Hs.eg.db)\nmapping &lt;- AnnotationDbi::select(org.Hs.eg.db, keys = keys(org.Hs.eg.db), columns = c(“GENENAME”, “ENSEMBL”, “SYMBOL”, “REFSEQ”))\nlibrary(biomaRt) mart &lt;- useMart(“ensembl”, dataset=“hsapiens_gene_ensembl”)\n\n\nbiomaRt can sometimes handle versioned IDs directly\nlistAttributes(mart) -&gt;atts\nmapping &lt;- getBM(attributes=c(“ensembl_gene_id”, “ensembl_gene_id_version”, “external_gene_name”, “description”), filters=“ensembl_gene_id_version”, values=tx2gene$GENEID, mart=mart)\n\n\nget differential eaxpression results data frame\nres_df &lt;- results(dds, contrast = c(“condition”, “other_condition”, “ctrl”), tidy = T)\nres_df_ann &lt;- res_df %&gt;% left_join(., mapping, by = c(“row” = “ensembl_gene_id_version”))\nlibrary(EnhancedVolcano) EnhancedVolcano(res_df_ann, lab = res_df_ann$external_gene_name, x = ‘log2FoldChange’, y = ‘padj’, pointSize = 2 )\n\n\nDifferential Modification Workflow\nsite_counts &lt;- filtered_genes %&gt;%\n  group_by(experiment, gene_id_clean, mod) %&gt;%\n  summarise(n_sites = n(), .groups = \"drop\") %&gt;%\n  left_join(mapped_reads, by = \"experiment\") %&gt;%\n  mutate(norm_sites = (n_sites / mapped) * 1e6) %&gt;% \n  mutate(\n    group = case_when(\n      str_detect(experiment, \"6|18|20\") ~ \"condition\",\n      str_detect(experiment, \"24|32|36\") ~ \"control_condition\",\n      TRUE ~ \"other\"\n    ),\n    replicate_group = case_when(\n      str_detect(experiment, \"1\") ~ \"control\",\n      str_detect(experiment, \"2\") ~ \"variable\",\n      TRUE ~ \"unknown\"\n    )\n  )\nsummary_stats &lt;- site_counts %&gt;% group_by(gene_id_clean, mod, group, replicate_group) %&gt;% summarise( mean_norm_sites = mean(norm_sites, na.rm = TRUE), sd_norm_sites = sd(norm_sites, na.rm = TRUE), n_replicates = n_distinct(experiment), .groups = “drop” )\n\n\n\nGene_of_interest &lt;- summary_stats_named %&gt;% filter(gene_symbol == “Gene_of_interest”) %&gt;% mutate( replicate_exposure = case_when( group == “condition” & replicate_group == “control” ~ “Control – Smokers”, group == “condition” & replicate_group == “CSE-exposed” ~ “CSE – Smokers”, group == “control” & replicate_group == “control” ~ “Control – Nonsmokers”, group == “control” & replicate_group == “CSE-exposed” ~ “CSE – Nonsmokers”, TRUE ~ NA_character_ ) ) %&gt;% drop_na(replicate_exposure)\n\n\n\nggplot(top5_m6a_df, aes(x = gene_symbol, y = mean_norm_sites, fill = replicate_exposure)) + geom_col(position = position_dodge(width = 0.8), color = “black”, width = 0.7) + scale_fill_manual(values = group_colors) + labs( title = “Coverage Normalized m6A Sites by Gene”, x = ““, y =”Normalized Sites (per million mapped reads)“, fill =”Condition” ) + theme_minimal() + theme( axis.text.x = element_text(size = 12, face = “bold”), legend.position = “bottom”, plot.title = element_text(size = 14, face = “bold”) )"
  },
  {
    "objectID": "scripts/Accuracy_Substitution_Plot.html",
    "href": "scripts/Accuracy_Substitution_Plot.html",
    "title": "Accuracy_Substitution_Plot",
    "section": "",
    "text": "Substitutionplot\nFull Pipeline to produce a plot showing accuracy of basecaller reads compared to reference.\nCreates the following graph \nUses multiple programs, will show full input/output to get to the graph\nFirst, run Dorado on the pod5/fast5 raw reads to produce a sam file\n./dorado \\\nbasecaller \\\n--models-directory /directory/to_location_of/dorado-1.0.1-linux-x64/rna004_130bps_sup@v5.2.0/ \\\nsup,inosine_m6A_2OmeA,2OmeG,m5C_2OmeC,pseU_2OmeU \\ #this will investigate all 8 mods currently available as of Dorado 1.0.1\n--min-qscore 10 \\ #min score removes bottom 90% of reads\n--emit-moves \\ #doesn't keep the eventalign files (unneeded and saves LOTS of space/memory)\n--estimate-poly-a \\ #adds polyA information to file for downstream processing\n-r \"/inputfile/location/pod5/\" \\\n&gt; \"/example/output/*_basecalled.bam\"\nUse this output to align to genome using Minimap2\nsamples=(\"list samples here\")\n\n# Paths\nminimap2=\"/path/to/minimap2\nref=\"/reference/file/*.transcripts.fa\"\nrawdir=\"/path/to/rawdata\"\nprocdir=\"/output/directory/for/processed_data/\"\n\n# Loop over each sample\nfor sample in \"${samples[@]}\"; do\n    echo \"Processing $sample...\"\n\n    fastq=\"${rawdir}/${sample}_8mod_basecalled.fastq\"\n    sam=\"${rawdir}/${sample}_8mod_aligned_splice.sam\"   #splice because we use -ax splice instead of -ax map-ont (seems to slightly improve the accuracy)\n    bam=\"${procdir}/${sample}_8mod_aligned_sortedsplice.bam\"\n\n    # Align with minimap2\n    \"$minimap2\" -ax splice -uf -k14 -y --secondary=no \"$ref\" \"$fastq\" &gt; \"$sam\"\n\n    # Convert to sorted BAM\n    samtools sort -o \"$bam\" \"$sam\"\n\n    # Get alignment stats\n    samtools flagstat \"$bam\"\n\n    echo \"Done with $sample.\"\n    echo \"---------------------------------------------\"\ndone\nImportant options -ax splice == spliced mapping [better for RNA] -uf -k14 == best options for noisy mRNA reads –secondary==no == removes secondary reads\n\nNext is MarginAlign/MarginStats, run on Python2.7.15 (old old), to find these statistical values\nfirst you must “uniquify” the fastq, removing any duplicate reads\n\"/path/to/marginAlign/scripts/uniquifyFastq\" \\\n\"/input/nonprocessed/*.fastq\" \\\n\"/processed/output/*uniquify.fastq\"\nUse the uniquify output to run marginStats\n\"/path/to/marginalign/marginStats\" \\\n--localAlignment \"/path/to/prev/output.bam\" \\\n\"/path/to/the/uniquified/file/.fastq\" \\\n\"/reference/file.fa\" \\\n--readIdentity \\\n--alignmentIdentity \\\n--readCoverage \\\n--readLength \\\n--printValuePerReadAlignment &gt; \"/output/testoutput.txt\"\nTo run the plot script, we must convert .txt into .tsv and convert all T into U to represent Uracil in RNA (current BAM files only can use T (thymine))\nsed 's/  */\\t/g' \"/sample/output.txt\" &gt; \"/sample/output.tsv\"\nsed 's/T/U/g'  \"/sample/output.tsv\" &gt; \"/sample/output_subU.tsv\" \n\n\n\nBEFORE RUNNING THE RSCRIPT\n*the tsv output from above has 4 lines of stats that you must remove for the plot to work. I have no clue why it adds these here but it will throw errors if not removed.\ntail -n +5 \"/sample/output_subU.tsv\" &gt; \"/sample/output_subU_cleaned.tsv\" \nUsing the below formatting, run the script in files as an R script to create the graph (this is currently set up for SLURM on UNIX to run Rscript). -The substitutionplot.R script\nRscript substitutionplot.R \\\n\"/sample/output_subU_cleaned.tsv\" \"/output/substitutionplot.tiff\" \\\n\"Substitution Matrix for reproducibility\" #title of graph"
  },
  {
    "objectID": "scripts/Substitutionplot.html",
    "href": "scripts/Substitutionplot.html",
    "title": "Substitutionplot",
    "section": "",
    "text": "&lt;img width=\"1024\" height=\"1536\" alt=\"Substitution Plot Jul 9, 2025\" src=\"https://github.com/user-attachments/assets/5e0a4fbe-6812-4c3f-ae4a-617e8cf9f60a\" /&gt;\n\nargs &lt;- commandArgs(trailingOnly = TRUE)\n\nlibrary(lattice)\n\nf &lt;- args[1]\nout &lt;- args[2]\ninf &lt;- args[3]\nprint(\"beginning panel function\")\n# Custom panel function with larger font size for text\nmyPanel &lt;- function(x, y, z, ...) {\n    panel.levelplot(x, y, z, ...)\n    # Increase font size using cex argument\n    panel.text(x, y, labels = paste(100 * round(exp(-z),4), \"%\", sep=\"\"), cex = 1.5) # Adjust cex for larger font\n}\n\n\nprint(\"reading data\")\n\nd &lt;- read.table(f, header = TRUE, row.names = 1)\n\n\n\nif (dim(d)[1] &gt; 0 && sum(d) &gt; 0) {\n    \nprint(\"plotting as tiff now\")\n    # Use tiff() instead of pdf(), specify resolution\n    tiff(filename = out, units = \"in\", width = 8, height = 6, res = 300)\nprint(\"making level plot or printing now\")\n    p &lt;- levelplot(as.matrix(-log(d)), main = inf, xlab = \"Reference bases\", ylab = \"Read bases\", panel = myPanel, col.regions = colorRampPalette(c(\"white\", \"red\"))(256))\n    \n    print(p)\n    \n    dev.off()\n    \n}"
  },
  {
    "objectID": "scripts/genome_assembly.html",
    "href": "scripts/genome_assembly.html",
    "title": "genome_assembly",
    "section": "",
    "text": "full pipeline for genome assembly (de novo & reference-based)\nlibrary prep for assembly (fastQC, fastp/fastplong, minimap2/flye)\n\n\nfor loop to perform fastQC\nfor file in /example/directory/*.fastq.gz\ndo\n    fastqc \"$file\" --threads 8 --outdir /example/output/fastQC/\ndone\n\n\n\nfor file in /example/directory/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    fastplong \\\n          -i \"$file\" \\\n          -o \"/example/output/$sample_trim.fastq.gz\" \\\n          --disable_adapter_trimming \\\n          -q 15 -l 30 -n 0 \\\n          --cut_front --cut_tail -M 20 -W 4 \\\n          --trim_poly_x \\\n          --json \"/output/${sample}_fastplong.json\" \\\n          --html \"/output/${sample}_fastplong.html\" \\\n          --thread 8 \n\n    echo \"$sample finished\"\ndone\n\n\n\nfor file in /example/rawdata/directory/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    sample=${fname%_R1_001.fastq.gz}\n    \n    r1_file=\"/example/file/one.fastq.gz\"\n    r2_file=\"/example/file/two.fastq.gz\"\n    \n    if [[ -f \"$r1_file\" && -f \"$r2_file\" ]]; then\n        echo \"Processing sample: $sample\"    \n        fastp \\\n              --in1 \"$r1_file\" \\\n              --in2 \"$r2_file\" \\\n              --out1 \"/example/output/one_clean.fastq.gz\" \\\n              --out2 \"/example/output/two_clean.fastq.gz\"  \\\n              --unpaired1 example/one.unpaired.fastq \\\n              --unpaired2 example/two.unpaired.fastq \\\n              --failed_out /example/failedreads/$sample.fastq \\\n              -q 30 -l 100 -n 2 -e 30 --cut_front --cut_tail -M 30 -W 1 \\\n              --trim_poly_g \\\n              --trim_poly_x \\\n              --dont_eval_duplication \\\n              --json \"/example/report/${sample}_fastp.json\" \\\n              --html \"/example/report/${sample}_fastp.html\" \\\n              --thread 8 \\\n    else\n        echo \"Warning: Missing R1 or R2 file for sample $sample\"\n    fi\ndone\nin1 and in2 == input files out1 and out2 == output files unpaired 1/2 == reads that didn’t fit both in1 and in2 failed == couldn’t read -q (Phred q score) -l 100 == minimum length of read to be counted -n 2 == at MAX 2 N reads (unknown nucleotide) per read without being disgarded –cut_front / cut_tail == cut out first nucleotides/adapter -M 30 == cuts above only if phred score &gt; 30. -W 1 == reading window of one, reads one nucleotide at a time –trim_poly_g / trim_poly_x == trim out polyG/polyX tails that may occur –dont_eval_duplication == doesn’t look for duplications to save memory (This was already done in fastQC/MultiQC steps)\n\n\n\nSame code as prior just change the input/outputs\n\n\n\nmultiqc -n illumina_multiqc -d /example/fastQC/fastp_data/\nmultiqc -n nanopore_multiqc -d /example/fastQC/fastplong_data/\n-n == the output files name -d == the input directory\n\n\n\n\n\n\nuse Flye program (install via conda/bioconda)\nfor file in /example/fastplong/data/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    flye --nano-hq \"$file\" \\\n        -g 12.3m \\\n        -o \"/scratch/gjandebeur/Cglabrata/flye/postfilter/${fname%}_nanopore.fastq\" \\\n        --threads 8\ndone\nOptions for FLYE include: -g == genome size expected (~12.3m for C. glabrata) -o == output file –threads (how many CPU you have listed)\n\n\nFirst for ONT data\n#for file in /example/rawdata/*fastq.gz\n#do\n#    if [ -f \"$file\" ]; then\n#    fname=$(basename \"$file\" .fastq.gz)\n#    echo \"Processing $fname...\"\n#    \n#    ./minimap2 -ax map-ont \\\n#    \"/REFERENCE/FILE.fasta\" \\\n#    \"$file\" &gt; /output/ONT/${fname}.sam\n#    fi\n#      echo \"minimap2 failed\"\n#done\nfor above; -ax map-ont == uses ONT mapping to genome"
  },
  {
    "objectID": "scripts/genome_assembly.html#to-perform-de-novo-assembly-of-genome-must-be-on-ont-data",
    "href": "scripts/genome_assembly.html#to-perform-de-novo-assembly-of-genome-must-be-on-ont-data",
    "title": "genome_assembly",
    "section": "",
    "text": "use Flye program (install via conda/bioconda)\nfor file in /example/fastplong/data/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    flye --nano-hq \"$file\" \\\n        -g 12.3m \\\n        -o \"/scratch/gjandebeur/Cglabrata/flye/postfilter/${fname%}_nanopore.fastq\" \\\n        --threads 8\ndone\nOptions for FLYE include: -g == genome size expected (~12.3m for C. glabrata) -o == output file –threads (how many CPU you have listed)\n\n\nFirst for ONT data\n#for file in /example/rawdata/*fastq.gz\n#do\n#    if [ -f \"$file\" ]; then\n#    fname=$(basename \"$file\" .fastq.gz)\n#    echo \"Processing $fname...\"\n#    \n#    ./minimap2 -ax map-ont \\\n#    \"/REFERENCE/FILE.fasta\" \\\n#    \"$file\" &gt; /output/ONT/${fname}.sam\n#    fi\n#      echo \"minimap2 failed\"\n#done\nfor above; -ax map-ont == uses ONT mapping to genome"
  },
  {
    "objectID": "scripts/genome_assembly.html#using-the-pileup-files-run-bcftools-call-for-snp-analysis",
    "href": "scripts/genome_assembly.html#using-the-pileup-files-run-bcftools-call-for-snp-analysis",
    "title": "genome_assembly",
    "section": "Using the pileup files, run bcftools call for SNP analysis",
    "text": "Using the pileup files, run bcftools call for SNP analysis\nvcf_dir=\"/path/to/bcfpileup/\"\noutput_dir=\"/output/path/bcfreport\"\n#\nfor vcf_file in \"$vcf_dir\"/*.vcf.gz\ndo\n    if [ -f \"$vcf_file\" ]; then\n        sample=$(basename \"$vcf_file\" .vcf.gz)\n        output_file=\"$output_dir/final_variants_${sample}.vcf.gz\"\n\n        # Skip if output file already exists\n        if [ -f \"$output_file\" ]; then\n            echo \"Skipping $sample - output already exists: $output_file\"\n            continue\n        fi\n\n        echo \"Processing sample: $sample\"\n        bcftools call \\\n            --threads 8 \\\n            --ploidy 1 \\ #this is for haploid, may need to change it!\n            -mv \\\n            -O z \\\n            -o \"$output_file\" \"$vcf_file\"\n    fi\ndone\necho “script complete”"
  },
  {
    "objectID": "scripts/Modkit_Analysis_dRNAseq.html",
    "href": "scripts/Modkit_Analysis_dRNAseq.html",
    "title": "Modkit_Analysis_dRNAseq",
    "section": "",
    "text": "dRNA_analyses\nWorkflow for analyses of m6A Modifications Post Modkit Filtering\nload dependencies first\nlibrary(data.table)\nlibrary(tidyverse) \nlibrary(tidytable)\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(GenomicRanges)\nlibrary(txdbmaker)\nsetwd and import m6A_subset from “m6A_subset_allstats.tsv”\n\nPlot data from filtered file, coverage & percent modified\nThis can and should be scaled up with more modification types and samples\nggplot(m6A_subset, aes(x = avg_n_valid_cov, y = avg_percent_modified, color = mod)) +\n  geom_smooth(method = \"gam\", formula = y ~ s(x, bs = \"cs\"), se = FALSE, linewidth = 1.2) +\n  scale_x_log10(limits = c(10, 10000)) +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(\n    x = \"Valid Coverage (log10)\",\n    y = \"Percent Modified\",\n    color = \"Modification\",\n    title = \"Coverage and Percent Modification\"\n  ) +\n  theme_classic(base_size = 14)\n\nload in txdb from gtf file (provided in files)\ntxdb &lt;- makeTxDbFromGFF(\"at_ensembl_plants.gtf\")\nk &lt;- keys(txdb, keytype = \"TXNAME\")  \ntx2gene_at &lt;- AnnotationDbi::select(txdb, keys = k, columns = \"GENEID\", keytype = \"TXNAME\")\nintersect txdb with the m6A_subset dataframe\n#intersecting files\nm6A_subset &lt;- m6A_subset %&gt;%\n  inner_join(., tx2gene_at, by=c(\"tx\"= \"TXNAME\")) %&gt;%\n  unite(position, chrom:end, remove =F) \n\n#changing format to make reproducible\nm6A_subset &lt;- m6A_subset %&gt;%\n  separate(position, into = c(\"chrom\", \"start\", \"end\"), sep = \"_\", remove = FALSE) %&gt;%\n  mutate(\n    start = as.integer(start),\n    end = as.integer(end)\n  )\n\n\nNow running Genomic Ranges to split tx into their genomic regions\nmods &lt;- GRanges(\n  seqnames = m6A_subset$chrom,\n  ranges = IRanges(start = m6A_subset$start, end = m6A_subset$end),\n  mod = m6A_subset$mod,\n  gene_id = m6A_subset$gene_id\n)\n\ncds_gr &lt;- cds(txdb)\nfive_utr_gr &lt;- fiveUTRsByTranscript(txdb, use.names = TRUE) |&gt; unlist()\nthree_utr_gr &lt;- threeUTRsByTranscript(txdb, use.names = TRUE) |&gt; unlist()\nintrons_gr &lt;- intronsByTranscript(txdb, use.names = TRUE) |&gt; unlist()\n\n\nNow running function to find each region’s hits\nassign_region &lt;- function(mods, cds, five_utr, three_utr, introns) {\n  region &lt;- rep(\"intergenic\", length(mods))  # default assignment\n\n  hits_cds &lt;- findOverlaps(mods, cds)\n  region[queryHits(hits_cds)] &lt;- \"CDS\"\n  hits_5utr &lt;- findOverlaps(mods, five_utr)\n  idx_5utr &lt;- setdiff(queryHits(hits_5utr), queryHits(hits_cds))\n  region[idx_5utr] &lt;- \"5'UTR\"  \n  hits_3utr &lt;- findOverlaps(mods, three_utr)\n  idx_3utr &lt;- setdiff(queryHits(hits_3utr), c(queryHits(hits_cds), idx_5utr))\n  region[idx_3utr] &lt;- \"3'UTR\"\n  \n  hits_introns &lt;- findOverlaps(mods, introns)\n  idx_introns &lt;- setdiff(queryHits(hits_introns), c(queryHits(hits_cds), idx_5utr, idx_3utr))\n  region[idx_introns] &lt;- \"intron\"\n  \n  return(region)\n}\n\n# add region tag to the original dataframe for downstream analyses\nm6A_subset$region &lt;- assign_region(mods_gr, cds_gr, five_utr_gr, three_utr_gr, introns_gr)\n\n#Lastly, filter by descending groups \nsummary_filtered_data_byregion &lt;-  m6A_subset %&gt;%\n  group_by(region, mod) %&gt;%\n  summarise(n_mods = n(), .groups = \"drop\") %&gt;%\n  arrange(desc(n_mods))\n\n# For overview of graph\ntable(m6A_subset$region)\n\n\nNow plotting genomic ranges\nregion_mod_summary &lt;- m6A_subset %&gt;%\n  group_by(region, mod) %&gt;%\n  summarise(n_mods = n(), .groups = \"drop\")\n\nfiltered_region_mod_summary &lt;- region_mod_summary %&gt;%\n  filter(mod %in% c(\"pseU\", \"m6A\"))\n\n#Now Actually Plot\n## This can be easily scaled up with other modification types or species\n\nggplot(filtered_region_mod_summary, aes(x = region, y = n_mods, fill = region)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \"Modification Counts per Region (pseU & m6A)\",\n    x = \"Genomic Region\",\n    y = NULL,\n    fill = \"Genomic Region\"\n  ) +\n  scale_fill_aaas() +\n  facet_wrap(~ mod, scales = \"free_y\") +\n  theme_minimal(24) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.text.x = element_blank()  # this removes tick labels under bars\n  )\n\n\n\nGO Enrichment Analyses\n#First load in GO term file to produce the background\n\nbackground &lt;- read_delim(\"arabidopsis_go_terms.txt\", \ndelim = \"\\t\", escape_double = FALSE,  \ntrim_ws = TRUE) %&gt;% \ndplyr::select(3,1) %&gt;% \ndplyr::rename(term = 1, gene = 2)\n\nm6a_genes &lt;- final_filtered_data %&gt;%\n   filter(mod == \"m6A\") %&gt;%\n   distinct(gene_id)\nm6a_genes &lt;- m6a_genes %&gt;%\n  mutate(gene_id = sub(\"^gene:\", \"\", gene_id))\nego &lt;- enricher(\n  m6a_genes$gene_id,\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  universe = background$gene,\n  minGSSize = 10,\n  maxGSSize = 500,\n  qvalueCutoff = 0.05,\n  gson = NULL,\n  TERM2GENE =  goterms\n  )\n\n\nhyper_ego &lt;- mutate(ego, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))\n\ndotplot(hyper_ego, x=\"FoldEnrichment\") +\n  ggtitle(\"m6A modified genes\") +\n  theme_cowplot(16)\n\n\n\nNext export the subset file as bed to run bedtools intersect (must be done unix) to line up with reference file and output as fasta\nm6A_subset %&gt;%\n  filter(code == \"a\") %&gt;%\n  dplyr::select(chrom, start, end, code, n_valid_cov, strand) %&gt;%\n  distinct(chrom, start, end, .keep_all = T) %&gt;%\n  arrange(chrom, start) %&gt;%\n  mutate(start = start - 3,\n         end = end + 3) %&gt;%\n  write.table(\"C:/extract/to/bedfile.bed\",\n              col.names = F, row.names = F, sep = \"\\t\", quote = F)\n\n\nNext code can NOT be run in RStudio, must export to a UNIX shell\nThe next part must be run on Unix with bedtools installed to run the intersect on the bed file with the known fasta reference\n./bedtools getfasta -s -fi \"reference_toplevel.fa\" -bed \"C:/extract/to/bedfile.bed\" &gt; \"bedfile_nowfa.fasta\"\n\nsamtools faidx bedfile_nowfa.fasta\"\n\n\nUsing pA lengths from original basecalling for analyses\nm6A_subset_tails &lt;- m6A_subset %&gt;%\n  mutate(\n    tail_length_group = case_when(\n      mean_tail_length &lt;= quantile(mean_tail_length, 0.25, na.rm = TRUE) ~ \"short\",\n      mean_tail_length &gt;= quantile(mean_tail_length, 0.75, na.rm = TRUE) ~ \"long\",\n      TRUE ~ \"medium\"\n    )\n  )\nAfter all library prep is done can plot multiple variables against, like plotting CPM, stoich, and polyA length (This graph has no correlation due to the subset but minor trends can be viewed with biological data)\nggplot(m6A_subset, aes(x = mean_CPM, y = tail_length)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  scale_x_log10() +\n  labs(title = \"Expression vs PolyA Tail Length (All Species)\", x = \"Mean CPM (log scale)\", y = \"Mean PolyA Tail Length\") +\n  theme_minimal(base_size = 14)"
  },
  {
    "objectID": "scripts/old_workflow.html",
    "href": "scripts/old_workflow.html",
    "title": "old_workflow",
    "section": "",
    "text": "full start to finish workflow for basecalling and minimapping for rna002 data designed for OSCER supercomputer, ignore batch script/slurm parts for local/others\n\n\n    #!/bin/bash\n    #SBATCH --partition=rnafold                       #where it runs (use \"rnafold\" or \"normal\")\n    #SBATCH --job-name=12samples_dorado                     #name your job \n    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename\n    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name\n    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do \"gpus-per-node=1\" \n    #SBATCH --time=24:00:00          #this just sets to 1 day  \n    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs\nI’ve installed all the software you will need so just copy and paste the path I provide as given and it’ll work (lmk if its prevented by permissions or anything)\nThe first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can’t write “U” so every call will say “T” instead but it means uracil.\nFor any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I’ve spent hours before looking at why my code wont run to find out this is why\nThe following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX). Just copy paste this chunk after the sbatch part but before the dorado script.\n        module load GCC\n        module load PyTorch\n        module load FlexiBLAS/3.3.1-GCC-12.3.0  \n        module load FFmpeg/4.4.2-GCCcore-11.3.0 \n        module load HTSlib\n        module load protobuf\n\n        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too\nTo run dorado youll follow this formatting for reference, adding “\\” to the end of the line tells your system that the command isn’t done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.\n#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado\" \\ \n        basecaller \\ \n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/\" \\\n        --min-qscore 10 \\\n        --emit-fastq &gt; \"/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq\"  \nif you ever chose to do modifications then u have to remove the “–emit-fastq” tag and change the output to be a “.bam”, as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.\nI prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the “&gt;” as it says redirect this entire command into this output.\nA qscore of 10 only keeps calls &gt;=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.\nThe next step is minimap2, where you take the fastq output and align it to your reference. I’ll attach the path for the human transcriptome/genome, but I don’t have the viral reference.\n                        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2\" \\\n        -ax splice -uf -k14 -y --secondary=no \\     #keep these settings. its importnat\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa\" \\ #this is your ref file (MUST BE .fasta or .fa) \n        \"/this/is/your/dorado/output/that/your/mapping.fastq\" &gt; \"               \"/this/is/your/output/alignedsplice.sam    \nIf you would rather use the transcriptome I’ll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it path : “/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa”\nThe output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant).\nNext step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).\noutput goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters. output must be .bam and input is the .sam\n        samtools sort -o \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\" \"/This/is/input/alignedsplice.sam\" \n\n        samtools flagstat  \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\"  \nFlagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you’ll need comparing the viral reference to using genome or transcriptome."
  },
  {
    "objectID": "scripts/old_workflow.html#beginning-batch-script-to-run-on-slurm",
    "href": "scripts/old_workflow.html#beginning-batch-script-to-run-on-slurm",
    "title": "old_workflow",
    "section": "",
    "text": "#!/bin/bash\n    #SBATCH --partition=rnafold                       #where it runs (use \"rnafold\" or \"normal\")\n    #SBATCH --job-name=12samples_dorado                     #name your job \n    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename\n    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name\n    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do \"gpus-per-node=1\" \n    #SBATCH --time=24:00:00          #this just sets to 1 day  \n    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs\nI’ve installed all the software you will need so just copy and paste the path I provide as given and it’ll work (lmk if its prevented by permissions or anything)\nThe first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can’t write “U” so every call will say “T” instead but it means uracil.\nFor any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I’ve spent hours before looking at why my code wont run to find out this is why\nThe following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX). Just copy paste this chunk after the sbatch part but before the dorado script.\n        module load GCC\n        module load PyTorch\n        module load FlexiBLAS/3.3.1-GCC-12.3.0  \n        module load FFmpeg/4.4.2-GCCcore-11.3.0 \n        module load HTSlib\n        module load protobuf\n\n        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too\nTo run dorado youll follow this formatting for reference, adding “\\” to the end of the line tells your system that the command isn’t done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.\n#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado\" \\ \n        basecaller \\ \n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/\" \\\n        --min-qscore 10 \\\n        --emit-fastq &gt; \"/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq\"  \nif you ever chose to do modifications then u have to remove the “–emit-fastq” tag and change the output to be a “.bam”, as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.\nI prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the “&gt;” as it says redirect this entire command into this output.\nA qscore of 10 only keeps calls &gt;=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.\nThe next step is minimap2, where you take the fastq output and align it to your reference. I’ll attach the path for the human transcriptome/genome, but I don’t have the viral reference.\n                        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2\" \\\n        -ax splice -uf -k14 -y --secondary=no \\     #keep these settings. its importnat\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa\" \\ #this is your ref file (MUST BE .fasta or .fa) \n        \"/this/is/your/dorado/output/that/your/mapping.fastq\" &gt; \"               \"/this/is/your/output/alignedsplice.sam    \nIf you would rather use the transcriptome I’ll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it path : “/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa”\nThe output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant).\nNext step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).\noutput goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters. output must be .bam and input is the .sam\n        samtools sort -o \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\" \"/This/is/input/alignedsplice.sam\" \n\n        samtools flagstat  \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\"  \nFlagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you’ll need comparing the viral reference to using genome or transcriptome."
  },
  {
    "objectID": "scripts/old_workflow.html#this-is-copy-pasted-from-my-script-but-theres-only-like-3-parts-youll-need-to-change-ive-already-combined-the-deseq2-and-volcano-plot-step-into-one-so-you-should-only-have-to-update-the-parts-of-the-following-code-that-ive-commented.",
    "href": "scripts/old_workflow.html#this-is-copy-pasted-from-my-script-but-theres-only-like-3-parts-youll-need-to-change-ive-already-combined-the-deseq2-and-volcano-plot-step-into-one-so-you-should-only-have-to-update-the-parts-of-the-following-code-that-ive-commented.",
    "title": "old_workflow",
    "section": "This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I’ve commented.",
    "text": "This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I’ve commented.\n    library(txdbmaker)\n    library(GenomicFeatures)\n    \n#*GTF file with annotated transcripts/regions*\n  \n    txdb &lt;- makeTxDbFromGFF(\"gencode.v47.annotation.gtf\")\n\n    k &lt;- keys(txdb, keytype = \"TXNAME\")  # make sure keytype exists\n    tx2gene &lt;- AnnotationDbi::select(txdb, keys = k, columns = \"GENEID\", keytype = \"TXNAME\")\nmetadata is just sample and condition listed in “ format”\n    library(tidyverse)\n    metadata &lt;- read_delim(\"metadata.txt\", delim = \"\\t\", \n                       escape_double = FALSE, trim_ws = TRUE)\n\n\n    setwd(\"C:/Users/gjand/Downloads/Schroeder_Lab/data/salmonm6a\")\n    files &lt;- paste(metadata$run, \"/quant.sf\", sep = \"\")\n    library(tximport)\n    txi &lt;- tximport(files, type = \"salmon\", tx2gene = tx2gene, txOut = F, ignoreAfterBar = T)\n\n    txi$counts |&gt; head()\n\n\n\n    library(DESeq2)\n    metadata$individual &lt;- as.factor(metadata$individual)\n\n    #  prepare deseq object\n    dds &lt;- DESeqDataSetFromTximport(txi = txi, colData = metadata, \n                                design = ~individual + condition)\n\n    dds &lt;- DESeq(dds, parallel = T)\n\n\n    # non batch corrected PCA\n    vsd &lt;- rlog(dds, blind = F)\n    pca_data &lt;- plotPCA(vsd, intgroup = c(\"condition\", \"individual\"), returnData = TRUE)\n    percentVar &lt;- round(100 * attr(pca_data, \"percentVar\"))\n    library(cowplot)\n    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +\n      geom_point(size = 3) +\n      xlab(paste0(\"PC1: \", percentVar[1], \"% variance\")) +\n      ylab(paste0(\"PC2: \", percentVar[2], \"% variance\")) +\n      ggtitle(\"Principal Component Analysis\") +\n     # scale_color_manual(values = c(\"black\", \"gray65\", \"darkblue\", \"cadetblue3\", \"springgreen4\", \"springgreen2\")) +\n      theme(aspect.ratio = 1) +\n      theme_cowplot(24) \n    # stat_ellipse(aes(group = Condition), type = \"t\", level = 0.65)\n\n    # ggsave(plot = last_plot(),\n    #        \"/name/of/save/output/path.png\",\n    #        width = 12, height = 9, units = \"in\", dpi =300, bg = \"white\")\n########################\nPCA to measure correlation between samples (need to remove batch-effect from individuals so that condition is the main difference)\n        # Batch corrected PCA\n    vsd &lt;- rlog(dds, blind = F)\n    assay(vsd) &lt;- limma::removeBatchEffect(assay(vsd), vsd$individual)\n    pca_data &lt;- plotPCA(vsd, intgroup = c(\"condition\", \"individual\"), returnData = TRUE)\n    percentVar &lt;- round(100 * attr(pca_data, \"percentVar\"))\n\n    # Custom PCA plot\n    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +\n      geom_point(size = 6) +\n      xlab(paste0(\"PC1: \", percentVar[1], \"% variance\")) +\n      ylab(paste0(\"PC2: \", percentVar[2], \"% variance\")) +\n      ggtitle(\"Principal Component Analysis\") +\n      theme(aspect.ratio = 1) +\n      theme_cowplot(24) +\n      stat_ellipse(type = \"t\", level = 0.95)\n\n    # ggsave(plot = last_plot(),\n    #        \"/name/of/save/output/path.png\",\n    #        width = 12, height = 9, units = \"in\", dpi =300, bg = \"white\")\n\n    library(org.Hs.eg.db)\n\n    mapping &lt;- AnnotationDbi::select(org.Hs.eg.db, keys = keys(org.Hs.eg.db),\n                                 columns = c(\"GENENAME\", \"ENSEMBL\", \"SYMBOL\", \"REFSEQ\"))\n\n\n    library(biomaRt)\n    mart &lt;- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n\n    # biomaRt can sometimes handle versioned IDs directly\n    listAttributes(mart) -&gt;atts\n\n    mapping &lt;- getBM(attributes=c(\"ensembl_gene_id\", \"ensembl_gene_id_version\", \"external_gene_name\",\n                              \"description\"),\n                 filters=\"ensembl_gene_id_version\",\n               values=tx2gene$GENEID,\n                 mart=mart)\n\n\n\n    # get differential eaxpression results data frame\n    res_df &lt;- results(dds, contrast = c(\"condition\", \"smoke\", \"ctrl\"), tidy = T)\n\n    res_df_ann &lt;- res_df %&gt;%\n      left_join(., mapping, by = c(\"row\" = \"ensembl_gene_id_version\"))\n\n\n    library(EnhancedVolcano)\n    EnhancedVolcano(res_df_ann,\n                lab = res_df_ann$external_gene_name,\n                x = 'log2FoldChange',\n                y = 'padj',\n                pointSize = 2\n                )\n    # \n\n        cat(\"All steps completed.\\n\")"
  },
  {
    "objectID": "scripts/Stoich_Analysis.html#fixing-for-reproducibility",
    "href": "scripts/Stoich_Analysis.html#fixing-for-reproducibility",
    "title": "Stoich_Analysis",
    "section": "fixing for reproducibility",
    "text": "fixing for reproducibility\nfiltered_mods &lt;- readr::read_csv(filtered_mod_file) %&gt;% mutate(gene_id = str_remove(gene_id, “^gene:”))\n\npercent modified should be present but if not here is calc for site-level stoich\nnative_stoich &lt;- native_filtered %&gt;% select(position, n_valid_cov, n_mod_reads, GENEID, mod, experiment) %&gt;% mutate( stoich = n_mod_reads / n_valid_cov, GENEID = str_remove(GENEID, “^gene:”) )"
  },
  {
    "objectID": "scripts/Stoich_Analysis.html#basic-graph",
    "href": "scripts/Stoich_Analysis.html#basic-graph",
    "title": "Stoich_Analysis",
    "section": "basic graph",
    "text": "basic graph"
  },
  {
    "objectID": "scripts/Stoich_Analysis.html#histogram-of-site-level-stoich-combines-all-samples",
    "href": "scripts/Stoich_Analysis.html#histogram-of-site-level-stoich-combines-all-samples",
    "title": "Stoich_Analysis",
    "section": "histogram of site level stoich, combines all samples",
    "text": "histogram of site level stoich, combines all samples\nggplot(native_stoich, aes(x = stoich)) + geom_histogram(bins = 40, fill = “steelblue”, color = “black”) + labs( title = “Stoichiometry Distribution”, x = “Stoichiometry”, y = “Count” ) + theme_minimal()"
  },
  {
    "objectID": "scripts/motif_analysis.html",
    "href": "scripts/motif_analysis.html",
    "title": "motif_analysis",
    "section": "",
    "text": "investigation of motif for each sample/species\n\n\ndependencies\nlibrary(stringr) library(dplyr) library(ggplot2)\n\n\nprevents scientific notation in graph\noptions(scipen=999)\n\n\nproducing updated bedfiles\n\n\nchange code from 17802 (pseU) to a (m6A) if preferred\nnative_filtered %&gt;% filter(code == “17802”) %&gt;% select(chrom, start, end, code, n_valid_cov, strand) %&gt;% distinct(chrom, start, end, .keep_all = TRUE) %&gt;% arrange(chrom, start) %&gt;% mutate( start = start - 3, end = end + 3 ) %&gt;% write.table( “./for_motif/at_pseU_3pad.bed”, col.names = FALSE, row.names = FALSE, sep = “, quote = FALSE )\n\nthis is IVT motif samples that are NOT found in the native replicates\nivt_antifiltered %&gt;% filter(code == “17802”) %&gt;% select(chrom, start, end, code, n_valid_cov, strand) %&gt;% distinct(chrom, start, end, .keep_all = TRUE) %&gt;% arrange(chrom, start) %&gt;% mutate( start = start - 3, end = end + 3 ) %&gt;% write.table( “./for_motif/at_pseU_IVT_3pad.bed”, col.names = FALSE, row.names = FALSE, sep = “, quote = FALSE )\n\n\n\nFOLLOWING THIS IS 1 SMALL IMPORTANT STEP. Can use MEME for motif analyses OR\n\n\nUse a UNIX SSH to run bedtools intersect with the updated fasta reference file to generate bed2fasta files (.fasta)\n\n\nafter producing fasta files in a seperate SSH that is UNIX rather than R.\n#read the files created, change pseU for m6A if needed\nlines &lt;- readLines(“./for_motif/at_pseU_3pad.fa”) IVT_lines &lt;- readLines(“./for_motif/at_pseU_IVT_3pad.fa”)\n\nsmall filtering for the files above\nstopifnot(length(lines) %% 2 == 0) stopifnot(length(IVT_lines) %% 2 == 0)\nheaders &lt;- lines[seq(1, length(lines), by = 2)] motifs &lt;- lines[seq(2, length(lines), by = 2)]\nIVT_headers &lt;- IVT_lines[seq(1, length(IVT_lines), by = 2)] IVT_motifs &lt;- IVT_lines[seq(2, length(IVT_lines), by = 2)]\nparsed &lt;- str_match(headers, “^&gt;([^:]+):(\\d+)-(\\d+)\\(([+-])\\)”) IVT_parsed &lt;- str_match(IVT_headers, “^&gt;([^:]+):(\\d+)-(\\d+)\\(([+-])\\)”)\n\nnow transform into df for graphing.\nat_pseU_3pad &lt;- data.frame( chrom = paste0(“chr”, parsed[, 2]), start = as.integer(parsed[, 3]), end = as.integer(parsed[, 4]), strand = parsed[, 5], motif = motifs, stringsAsFactors = FALSE )\nat_pseU_IVT_3pad &lt;- data.frame( chrom = paste0(“chr”, IVT_parsed[, 2]), start = as.integer(IVT_parsed[, 3]), end = as.integer(IVT_parsed[, 4]), strand = IVT_parsed[, 5], motif = IVT_motifs, stringsAsFactors = FALSE )\n\n\ncollapse down to 5mer (uses 7mer at first for safety, but ONT pores are 5mers)\nat_pseU_2pad &lt;- at_pseU_3pad %&gt;% mutate( start = start + 1, end = end - 1, motif = substr(motif, 2, nchar(motif) - 1) )\nat_pseU_IVT_2pad &lt;- at_pseU_IVT_3pad %&gt;% mutate( start = start + 1, end = end - 1, motif = substr(motif, 2, nchar(motif) - 1) )\n\n\n\nview which motifs are shared between the two (quality control step)\nshared_motifs &lt;- intersect( unique(at_pseU_2pad\\(motif),\n  unique(at_pseU_IVT_2pad\\)motif) )\nat_pseU_2pad_shared &lt;- at_pseU_2pad %&gt;% filter(motif %in% shared_motifs)\nat_pseU_IVT_2pad_shared &lt;- at_pseU_IVT_2pad %&gt;% filter(motif %in% shared_motifs)\n\n\ncount unique motifs and their percent of total motif\nmotif_ranked_top25 &lt;- at_pseU_2pad %&gt;% group_by(motif) %&gt;% summarise(count = n()) %&gt;% mutate( dataset = “Arabidopsis”, percent = count / sum(count) * 100 )\nIVT_motif_ranked_top25 &lt;- at_pseU_IVT_2pad %&gt;% group_by(motif) %&gt;% summarise(count = n()) %&gt;% mutate( dataset = “IVT”, percent = count / sum(count) * 100 )\n\n\ncombine into 1 dataset\ncombined_motifs &lt;- bind_rows( motif_ranked_top25 %&gt;% select(motif, percent, dataset), IVT_motif_ranked_top25 %&gt;% select(motif, percent, dataset) )\n\n\nlimits to top 25 motifs, can change n= to any number\ntop_motifs &lt;- combined_motifs %&gt;% group_by(motif) %&gt;% summarise(avg_percent = mean(percent)) %&gt;% arrange(desc(avg_percent)) %&gt;% slice_head(n = 25) %&gt;% pull(motif)\n\nexample graph to produce to show these motifs\ncombined_motifs %&gt;% filter(motif %in% top_motifs) %&gt;% mutate(motif = factor(motif, levels = rev(top_motifs))) %&gt;% ggplot(aes(x = percent, y = motif, fill = dataset)) + geom_col(position = position_dodge(width = 0.8)) + labs( title = “Top 25 pseU 5-mer Motif Frequencies (Normalized)”, x = “Percent of Total Sites”, y = “Motif” ) + theme_minimal() + theme( plot.title = element_text(size = 14, face = “bold”), axis.text.y = element_text(size = 10), legend.position = “top” )"
  },
  {
    "objectID": "scripts/pA_analysis.html#dependencies",
    "href": "scripts/pA_analysis.html#dependencies",
    "title": "pA_analysis",
    "section": "dependencies",
    "text": "dependencies\nsuppressPackageStartupMessages({ library(data.table) library(tidyverse) library(tidytable) library(ggplot2) library(stringr) library(dplyr) })\n\nload in pA tail lengths for each sample\npolyA_data &lt;- readr::read_tsv(“data/polyA_tail_lengths.tsv”) %&gt;% rename( tail_length = , # &lt;– Replace with actual column name gene_annotation =  # &lt;– if gene info is embedded here ) %&gt;% mutate( gene_id = str_extract(gene_annotation, ‘gene_id “gene:[^\"]+’) %&gt;% str_replace(’gene_id”gene:’, ““) ) %&gt;% filter(!is.na(tail_length), !is.na(gene_id))\n\nload the final filtered data from the library preprocessing script.\nfinal_filtered_data &lt;- readr::read_csv(“data/final_filtered_data.csv”)"
  },
  {
    "objectID": "scripts/pA_analysis.html#seperating-pa-length-into-3-categories-seperated-by-q1-q1-q3-and-q3-as-short-medium-and-long",
    "href": "scripts/pA_analysis.html#seperating-pa-length-into-3-categories-seperated-by-q1-q1-q3-and-q3-as-short-medium-and-long",
    "title": "pA_analysis",
    "section": "seperating pA length into 3 categories, seperated by <Q1 , Q1-Q3, and >Q3 as “short”, “medium”, and “long”",
    "text": "seperating pA length into 3 categories, seperated by &lt;Q1 , Q1-Q3, and &gt;Q3 as “short”, “medium”, and “long”\ngene_level_tails &lt;- polyA_data %&gt;% group_by(gene_id) %&gt;% summarise( mean_tail_length = mean(tail_length, na.rm = TRUE), median_tail_length = median(tail_length, na.rm = TRUE), .groups = “drop” ) %&gt;% mutate( tail_length_group = case_when( mean_tail_length &lt;= quantile(mean_tail_length, 0.25, na.rm = TRUE) ~ “short”, mean_tail_length &gt;= quantile(mean_tail_length, 0.75, na.rm = TRUE) ~ “long”, TRUE ~ “medium” ) )"
  },
  {
    "objectID": "scripts/pA_analysis.html#combine-the-two-files-for-graphing-and-join-by-gene_id-important",
    "href": "scripts/pA_analysis.html#combine-the-two-files-for-graphing-and-join-by-gene_id-important",
    "title": "pA_analysis",
    "section": "combine the two files for graphing and join by gene_id (important)",
    "text": "combine the two files for graphing and join by gene_id (important)\nmod_with_tail &lt;- filtered_mods %&gt;% left_join(gene_level_tails %&gt;% select(gene_id, tail_length_group), by = “gene_id”) %&gt;% filter(!is.na(tail_length_group))\n\nbasic distribution of pA lengths\nggplot(gene_level_tails, aes(x = mean_tail_length)) + geom_histogram(binwidth = 5, fill = “steelblue”, color = “black”) + theme_minimal() + labs(title = “Distribution of Mean PolyA Tail Lengths (Per Gene)”, x = “Mean PolyA Tail Length (nt)”, y = “Gene Count”)\n\n\nand graph distributions of % mod to pA length, can change y axis to other columns as well\nggplot(mod_with_tail, aes(x = tail_length_group, y = avg_percent_modified, fill = tail_length_group)) + geom_violin(trim = FALSE, alpha = 0.8, color = NA) + geom_boxplot(width = 0.1, outlier.shape = NA, fill = “white”, color = “gray20”, alpha = 0.5) + facet_wrap(~ mod, scales = “free_y”) + theme_minimal(base_size = 13) + labs( title = “% Modified by PolyA Tail Length Group”, x = “PolyA Tail Length Group”, y = “Average % Modified” ) + scale_fill_brewer(palette = “Set2”) + theme(legend.position = “none”)"
  },
  {
    "objectID": "scripts/exon_length.html",
    "href": "scripts/exon_length.html",
    "title": "exon_length",
    "section": "",
    "text": "determining exon lengths in methylated vs unmethylated samples\n\ndependencies\nlibrary(GenomicFeatures) library(dplyr) library(stringr) library(ggplot2)\n\n\n\nload in txdb (change to your gtf for species studied)\ntxdb &lt;- makeTxDbFromGFF(“../data/at_ensembl_plants.gtf”)\n\n\nextract exon length from txdb file\nexons_df &lt;- exons(txdb, columns = c(“EXONID”, “TXNAME”, “GENEID”)) %&gt;% as.data.frame() exons_df_clean &lt;- exons_df %&gt;% rename( chrom = seqnames, exon_start = start, exon_end = end ) %&gt;% mutate( exon_length = exon_end - exon_start + 1, GENEID = str_remove(GENEID, “^gene:”) )\n\n\nisolate m6A sites from native_filtered (produced in libraryprep_analyses.R)\nm6A_sites &lt;- native_filtered %&gt;% filter(mod == “m6A”) %&gt;% mutate(GENEID = str_remove(GENEID, “^gene:”)) %&gt;% select(GENEID, m6a_pos = start)\n\n\n\n\n\ndetermine which transcripts are methylated or unmethylated\nmethylated_exons &lt;- exons_df_clean %&gt;% inner_join(m6A_sites, by = “GENEID”) %&gt;% filter(m6a_pos &gt;= exon_start & m6a_pos &lt;= exon_end) %&gt;% distinct(chrom, exon_start, exon_end, GENEID, .keep_all = TRUE)\n\n\nIdentify unmethylated exons (exons without any m6A sites)\nunmethylated_exons &lt;- anti_join( exons_df_clean, methylated_exons, by = c(“chrom”, “exon_start”, “exon_end”, “GENEID”) )\n\n\n#produce one combined length file with both meth/unmeth lengths\nlength_df &lt;- bind_rows( methylated_exons %&gt;% select(exon_length) %&gt;% mutate(type = “methylated”), unmethylated_exons %&gt;% select(exon_length) %&gt;% mutate(type = “unmethylated”) )\n\n\nexample plot to view the difference in length (violin & boxplot)\nggplot(length_df, aes(x = type, y = exon_length, fill = type)) + geom_violin(trim = FALSE, alpha = 0.7) + geom_boxplot(width = 0.1, outlier.shape = NA, fill = “white”) + labs( title = “Exon Lengths: m6A Methylated vs Unmethylated”, x = NULL, y = “Exon Length (nt)” ) + scale_fill_manual(values = c(methylated = “darkgreen”, unmethylated = “maroon”)) + coord_cartesian(ylim = c(0, 2000)) + theme_minimal()"
  },
  {
    "objectID": "scripts/Modkit_Apptainer.html",
    "href": "scripts/Modkit_Apptainer.html",
    "title": "Modkit_Apptainer",
    "section": "",
    "text": "Installation of Modkit onto OSCER (uses singularity/apptainer) for dependency issues\nworkflow for running modkit on OSCER. Uses singularity/apptainer to update up to glibc2.18 so that modkit can run.\nHeres the path to the modkit installation,\n“/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/modkit_v0.5/dist_modkit_v0.5.0_5120ef7/modkit”\nIn order to run on OSCER you’ll need to create a container for glibc2.18 by copying the following. No clue how to explain what this does but you should be able to copy directly to create the image needed to run modkit\nmkdir -p /scratch/$USER/apptainer_images\napptainer pull /scratch/$USER/apptainer_images/ubuntu20.sif docker://ubuntu:20.04 \nexport APPTAINER_CACHEDIR=/scratch/$USER/apptainer_cache\nexport APPTAINER_TMPDIR=/scratch/$USER/apptainer_tmp \nmkdir -p $APPTAINER_CACHEDIR $APPTAINER_TMPDIR\nAfter this, you will bind the apptainer image that was just created in your scratch directory to the modkit download path above by doing the following, which will allow modkit to run without the glibc version mismatch. You can change the paths but /mnt/ must be first to make sure it’s pulling through the apptainer.\n    apptainer exec --bind /ourdisk:/mnt /scratch/gjandebeur/apptainer_images/ubuntu20.sif \\ \n/mnt/hpc/rnafold/gjandebeur/dont_archive/software/modkit_v0.5/dist_modkit_v0.5.0_5120ef7/modkit\npileup   –mod-thresholds a:0.99 –mod-thresholds m:0.99 –mod-thresholds 17802:0.99 –mod-thresholds 17596:0.99\n/mnt/hpc/rnafold/path/to/rawdata/aligned.bam\n/mnt/hpc/rnafold/path/to/rawdata/pileup.bed\nfor reference, a = m6A. m = m5C. 17802 = pseU. & 17596 = inosine_m6A"
  },
  {
    "objectID": "scripts/GO_analysis.html",
    "href": "scripts/GO_analysis.html",
    "title": "GO_analysis",
    "section": "",
    "text": "load dependencies\n\n\n\nlibrary(clusterProfiler) library(enrichplot) library(stringr) library(dplyr) #######################\n\n\nLoad in past library prep file\nnative_filtered &lt;- fread(“../data/native_filtered_clean.csv”, row.names = F)\n\n\nmod_gene_data &lt;- native_filtered %&gt;% mutate( gene_id = str_remove(GENEID, “^gene:”), mod = str_trim(mod) ) %&gt;% select(gene_id, mod, experiment) %&gt;% distinct() %&gt;% as.data.frame()\nmod_gene_list &lt;- mod_gene_data %&gt;% group_by(mod) %&gt;% summarise(genes = list(unique(gene_id))) %&gt;% as.data.frame()\nmod_gene_list_named &lt;- setNames(mod_gene_list\\(genes, mod_gene_list\\)mod) ############################################\n#begin enrichment code\nego &lt;- compareCluster( geneCluster = mod_gene_list_named, fun = “enricher”, universe = background$gene, pvalueCutoff = 0.05, TERM2GENE = goterms )\nhyper_ego &lt;- mutate(ego@compareClusterResult, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))\n\n\n#some potential graphs to help visualize #bubble plot\nlibrary(ggplot2) library(cowplot)\nggplot(ego, aes(x = Cluster, y = Description)) + geom_point(aes(size = Count, color = p.adjust)) + scale_color_gradient(low = “forestgreen”, high = “darkviolet”, name = “Adj p-value”) + theme_cowplot() + labs( title = “Ratio of GO Enrichment by Modification”, x = “Modification”, y = “GO Term”, size = “Gene Count” )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]