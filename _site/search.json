[
  {
    "objectID": "scripts.html",
    "href": "scripts.html",
    "title": "Scripts",
    "section": "",
    "text": "Collection of scripts I’ve written:\n\n\nOld Workflow\nR script for preprocessing\nView\n\n\nGenome Assembly\nR script for assembly analysis\nView"
  },
  {
    "objectID": "scripts/genome_assembly.html",
    "href": "scripts/genome_assembly.html",
    "title": "genome_assembly",
    "section": "",
    "text": "full pipeline for genome assembly (de novo & reference-based)\nlibrary prep for assembly (fastQC, fastp/fastplong, minimap2/flye)\n\n\nfor loop to perform fastQC\nfor file in /example/directory/*.fastq.gz\ndo\n    fastqc \"$file\" --threads 8 --outdir /example/output/fastQC/\ndone\n\n\n\nfor file in /example/directory/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    fastplong \\\n          -i \"$file\" \\\n          -o \"/example/output/$sample_trim.fastq.gz\" \\\n          --disable_adapter_trimming \\\n          -q 15 -l 30 -n 0 \\\n          --cut_front --cut_tail -M 20 -W 4 \\\n          --trim_poly_x \\\n          --json \"/output/${sample}_fastplong.json\" \\\n          --html \"/output/${sample}_fastplong.html\" \\\n          --thread 8 \n\n    echo \"$sample finished\"\ndone\n\n\n\nfor file in /example/rawdata/directory/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    sample=${fname%_R1_001.fastq.gz}\n    \n    r1_file=\"/example/file/one.fastq.gz\"\n    r2_file=\"/example/file/two.fastq.gz\"\n    \n    if [[ -f \"$r1_file\" && -f \"$r2_file\" ]]; then\n        echo \"Processing sample: $sample\"    \n        fastp \\\n              --in1 \"$r1_file\" \\\n              --in2 \"$r2_file\" \\\n              --out1 \"/example/output/one_clean.fastq.gz\" \\\n              --out2 \"/example/output/two_clean.fastq.gz\"  \\\n              --unpaired1 example/one.unpaired.fastq \\\n              --unpaired2 example/two.unpaired.fastq \\\n              --failed_out /example/failedreads/$sample.fastq \\\n              -q 30 -l 100 -n 2 -e 30 --cut_front --cut_tail -M 30 -W 1 \\\n              --trim_poly_g \\\n              --trim_poly_x \\\n              --dont_eval_duplication \\\n              --json \"/example/report/${sample}_fastp.json\" \\\n              --html \"/example/report/${sample}_fastp.html\" \\\n              --thread 8 \\\n    else\n        echo \"Warning: Missing R1 or R2 file for sample $sample\"\n    fi\ndone\nin1 and in2 == input files out1 and out2 == output files unpaired 1/2 == reads that didn’t fit both in1 and in2 failed == couldn’t read -q (Phred q score) -l 100 == minimum length of read to be counted -n 2 == at MAX 2 N reads (unknown nucleotide) per read without being disgarded –cut_front / cut_tail == cut out first nucleotides/adapter -M 30 == cuts above only if phred score &gt; 30. -W 1 == reading window of one, reads one nucleotide at a time –trim_poly_g / trim_poly_x == trim out polyG/polyX tails that may occur –dont_eval_duplication == doesn’t look for duplications to save memory (This was already done in fastQC/MultiQC steps)\n\n\n\nSame code as prior just change the input/outputs\n\n\n\nmultiqc -n illumina_multiqc -d /example/fastQC/fastp_data/\nmultiqc -n nanopore_multiqc -d /example/fastQC/fastplong_data/\n-n == the output files name -d == the input directory\n\n\n\n\n\n\nuse Flye program (install via conda/bioconda)\nfor file in /example/fastplong/data/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    flye --nano-hq \"$file\" \\\n        -g 12.3m \\\n        -o \"/scratch/gjandebeur/Cglabrata/flye/postfilter/${fname%}_nanopore.fastq\" \\\n        --threads 8\ndone\nOptions for FLYE include: -g == genome size expected (~12.3m for C. glabrata) -o == output file –threads (how many CPU you have listed)\n\n\nFirst for ONT data\n#for file in /example/rawdata/*fastq.gz\n#do\n#    if [ -f \"$file\" ]; then\n#    fname=$(basename \"$file\" .fastq.gz)\n#    echo \"Processing $fname...\"\n#    \n#    ./minimap2 -ax map-ont \\\n#    \"/REFERENCE/FILE.fasta\" \\\n#    \"$file\" &gt; /output/ONT/${fname}.sam\n#    fi\n#      echo \"minimap2 failed\"\n#done\nfor above; -ax map-ont == uses ONT mapping to genome\nNext minimap2 for Illumina paired reads (different syntax)\n#for file1 in \"/example/file2/illumina/*_R1_001*.fastq.gz\n#do\n#    if [ -f \"$file1\" ]; then\n#        base=\"${file1%_R1_001*.fastq.gz}\"\n#        base=$(basename \"$base\")\n#        file2=\"/example/file2/illumina/${base}_R2_001*.fastq.gz\"\n#        file2=$(ls $file2 2&gt;/dev/null | head -1)\n#        if [ -f \"$file2\" ]; then\n#            echo \"Processing paired files for sample: $base\"\n#            echo \"R1: $(basename $file1)\"\n#            echo \"R2: $(basename $file2)\"\n#            ./minimap -ax sr \\\n#            \"/REFERENCE/FILE.fasta\" \\\n#            \"$file1\" \"$file2\" &gt; /output/illumina/${base}.sam\n#            echo \"Generated: ${base}.sam\"\n#        else\n#            echo \"Warning: R2 file not found for $file1\"\n#            echo \"Expected: $file2\"\n#        fi\n#        echo \"---------------------------------------------\"\n#    fi\n#done\nfor above; -ax sr === mapping using paired reads (illumina) both file1/file2 must be paired data (not just two similar files)\n\n\nfor file in /example/input/from/minimap2/*.sam\ndo\n    fname=$(basename \"$file\" .sam)\n    bam=\"/example/output/filepath/bam/${fname}.bam\"\n    echo \"Converting $file to sorted BAM...\"\n    \n    # Add temp directory and memory limit\n    samtools sort -T /example/temporarydirectory/forsorting/tmp/${fname} -m 2G -o \"$bam\" \"$file\" || { echo \"Sort failed for $file\"; continue; }\n    \n    samtools index \"$bam\"\n    samtools flagstat \"$bam\"\n    echo \"Done with $fname.\"\n    echo \"---------------------------------------------\"\ndone\nfor file in /example/alldata/postfilter/*.bam\ndo\n  samtools flagstat\necho \"----------------------------------------------------\"\n\ndone\nAfter obtaining output files with the flagstat data, as well as from the Flye assembly, you can run the code attached to this directory to pull out statistical data and place into a .xlsx file for further analyses. THESE TWO FILES MENTIONED ABOVE MUST BE RUN AS PYTHON SCRIPTS\nNow Run BCFtools to mpileup reads\nref_dir=\"/pathto/reference\"\nbam_dir=\"/path/to/postfilter/ONT/bam\"\noutput_dir=\"/path/to/output/postfilter/bcfpileup/\"  \n\necho \"Starting bcf mpileup loop\"\n\nfor bam_file in \"$bam_dir\"/*.bam\ndo\n    if [ -f \"$bam_file\" ]; then\n        sample=$(basename \"$bam_file\" .bam)\n        output_file=\"$output_dir/${sample}.vcf.gz\"\n        \n        # Skip if output file already exists\n        if [ -f \"$output_file\" ]; then\n            echo \"Skipping $sample - output already exists: $output_file\"\n            continue\n        fi\n        \n        echo \"Processing sample: $sample\"\n        echo \"BAM file: $bam_file\"\n        \n        bcftools mpileup \\\n            --max-depth 1000000 \\\n            --threads 8 \\\n            -O z \\\n            -o \"$output_file\" \\\n            -f \"$ref_dir/referencefile.fasta\" \\\n            \"$bam_file\"\n        \n        echo \"Generated: ${sample}.vcf.gz\"\n        echo \"---------------------------------------------\"\n    fi\ndone\necho \"bcftools mpileup loop completed.\"\nUsing the pileup files, run bcftools call for SNP analysis"
  },
  {
    "objectID": "scripts/genome_assembly.html#to-perform-de-novo-assembly-of-genome-must-be-on-ont-data",
    "href": "scripts/genome_assembly.html#to-perform-de-novo-assembly-of-genome-must-be-on-ont-data",
    "title": "genome_assembly",
    "section": "",
    "text": "use Flye program (install via conda/bioconda)\nfor file in /example/fastplong/data/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    flye --nano-hq \"$file\" \\\n        -g 12.3m \\\n        -o \"/scratch/gjandebeur/Cglabrata/flye/postfilter/${fname%}_nanopore.fastq\" \\\n        --threads 8\ndone\nOptions for FLYE include: -g == genome size expected (~12.3m for C. glabrata) -o == output file –threads (how many CPU you have listed)\n\n\nFirst for ONT data\n#for file in /example/rawdata/*fastq.gz\n#do\n#    if [ -f \"$file\" ]; then\n#    fname=$(basename \"$file\" .fastq.gz)\n#    echo \"Processing $fname...\"\n#    \n#    ./minimap2 -ax map-ont \\\n#    \"/REFERENCE/FILE.fasta\" \\\n#    \"$file\" &gt; /output/ONT/${fname}.sam\n#    fi\n#      echo \"minimap2 failed\"\n#done\nfor above; -ax map-ont == uses ONT mapping to genome\nNext minimap2 for Illumina paired reads (different syntax)\n#for file1 in \"/example/file2/illumina/*_R1_001*.fastq.gz\n#do\n#    if [ -f \"$file1\" ]; then\n#        base=\"${file1%_R1_001*.fastq.gz}\"\n#        base=$(basename \"$base\")\n#        file2=\"/example/file2/illumina/${base}_R2_001*.fastq.gz\"\n#        file2=$(ls $file2 2&gt;/dev/null | head -1)\n#        if [ -f \"$file2\" ]; then\n#            echo \"Processing paired files for sample: $base\"\n#            echo \"R1: $(basename $file1)\"\n#            echo \"R2: $(basename $file2)\"\n#            ./minimap -ax sr \\\n#            \"/REFERENCE/FILE.fasta\" \\\n#            \"$file1\" \"$file2\" &gt; /output/illumina/${base}.sam\n#            echo \"Generated: ${base}.sam\"\n#        else\n#            echo \"Warning: R2 file not found for $file1\"\n#            echo \"Expected: $file2\"\n#        fi\n#        echo \"---------------------------------------------\"\n#    fi\n#done\nfor above; -ax sr === mapping using paired reads (illumina) both file1/file2 must be paired data (not just two similar files)\n\n\nfor file in /example/input/from/minimap2/*.sam\ndo\n    fname=$(basename \"$file\" .sam)\n    bam=\"/example/output/filepath/bam/${fname}.bam\"\n    echo \"Converting $file to sorted BAM...\"\n    \n    # Add temp directory and memory limit\n    samtools sort -T /example/temporarydirectory/forsorting/tmp/${fname} -m 2G -o \"$bam\" \"$file\" || { echo \"Sort failed for $file\"; continue; }\n    \n    samtools index \"$bam\"\n    samtools flagstat \"$bam\"\n    echo \"Done with $fname.\"\n    echo \"---------------------------------------------\"\ndone\nfor file in /example/alldata/postfilter/*.bam\ndo\n  samtools flagstat\necho \"----------------------------------------------------\"\n\ndone\nAfter obtaining output files with the flagstat data, as well as from the Flye assembly, you can run the code attached to this directory to pull out statistical data and place into a .xlsx file for further analyses. THESE TWO FILES MENTIONED ABOVE MUST BE RUN AS PYTHON SCRIPTS\nNow Run BCFtools to mpileup reads\nref_dir=\"/pathto/reference\"\nbam_dir=\"/path/to/postfilter/ONT/bam\"\noutput_dir=\"/path/to/output/postfilter/bcfpileup/\"  \n\necho \"Starting bcf mpileup loop\"\n\nfor bam_file in \"$bam_dir\"/*.bam\ndo\n    if [ -f \"$bam_file\" ]; then\n        sample=$(basename \"$bam_file\" .bam)\n        output_file=\"$output_dir/${sample}.vcf.gz\"\n        \n        # Skip if output file already exists\n        if [ -f \"$output_file\" ]; then\n            echo \"Skipping $sample - output already exists: $output_file\"\n            continue\n        fi\n        \n        echo \"Processing sample: $sample\"\n        echo \"BAM file: $bam_file\"\n        \n        bcftools mpileup \\\n            --max-depth 1000000 \\\n            --threads 8 \\\n            -O z \\\n            -o \"$output_file\" \\\n            -f \"$ref_dir/referencefile.fasta\" \\\n            \"$bam_file\"\n        \n        echo \"Generated: ${sample}.vcf.gz\"\n        echo \"---------------------------------------------\"\n    fi\ndone\necho \"bcftools mpileup loop completed.\"\nUsing the pileup files, run bcftools call for SNP analysis"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gjandebeur’s Github",
    "section": "",
    "text": "Current PhD Student at OUHSC interested in computational biology and bioinformatics\nCollection of Projects I’ve worked on."
  },
  {
    "objectID": "scripts/old_workflow.html",
    "href": "scripts/old_workflow.html",
    "title": "old_workflow",
    "section": "",
    "text": "full start to finish workflow for basecalling and minimapping for rna002 data designed for OSCER supercomputer, ignore batch script/slurm parts for local/others\n\n\n    #!/bin/bash\n    #SBATCH --partition=rnafold                       #where it runs (use \"rnafold\" or \"normal\")\n    #SBATCH --job-name=12samples_dorado                     #name your job \n    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename\n    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name\n    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do \"gpus-per-node=1\" \n    #SBATCH --time=24:00:00          #this just sets to 1 day  \n    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs\nI’ve installed all the software you will need so just copy and paste the path I provide as given and it’ll work (lmk if its prevented by permissions or anything)\nThe first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can’t write “U” so every call will say “T” instead but it means uracil.\nFor any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I’ve spent hours before looking at why my code wont run to find out this is why\nThe following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX). Just copy paste this chunk after the sbatch part but before the dorado script.\n        module load GCC\n        module load PyTorch\n        module load FlexiBLAS/3.3.1-GCC-12.3.0  \n        module load FFmpeg/4.4.2-GCCcore-11.3.0 \n        module load HTSlib\n        module load protobuf\n\n        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too\nTo run dorado youll follow this formatting for reference, adding “\\” to the end of the line tells your system that the command isn’t done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.\n#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado\" \\ \n        basecaller \\ \n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/\" \\\n        --min-qscore 10 \\\n        --emit-fastq &gt; \"/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq\"  \nif you ever chose to do modifications then u have to remove the “–emit-fastq” tag and change the output to be a “.bam”, as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.\nI prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the “&gt;” as it says redirect this entire command into this output.\nA qscore of 10 only keeps calls &gt;=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.\nThe next step is minimap2, where you take the fastq output and align it to your reference. I’ll attach the path for the human transcriptome/genome, but I don’t have the viral reference.\n                        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2\" \\\n        -ax splice -uf -k14 -y --secondary=no \\     #keep these settings. its importnat\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa\" \\ #this is your ref file (MUST BE .fasta or .fa) \n        \"/this/is/your/dorado/output/that/your/mapping.fastq\" &gt; \"               \"/this/is/your/output/alignedsplice.sam    \nIf you would rather use the transcriptome I’ll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it path : “/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa”\nThe output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant).\nNext step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).\noutput goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters. output must be .bam and input is the .sam\n        samtools sort -o \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\" \"/This/is/input/alignedsplice.sam\" \n\n        samtools flagstat  \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\"  \nFlagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you’ll need comparing the viral reference to using genome or transcriptome."
  },
  {
    "objectID": "scripts/old_workflow.html#beginning-batch-script-to-run-on-slurm",
    "href": "scripts/old_workflow.html#beginning-batch-script-to-run-on-slurm",
    "title": "old_workflow",
    "section": "",
    "text": "#!/bin/bash\n    #SBATCH --partition=rnafold                       #where it runs (use \"rnafold\" or \"normal\")\n    #SBATCH --job-name=12samples_dorado                     #name your job \n    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename\n    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name\n    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do \"gpus-per-node=1\" \n    #SBATCH --time=24:00:00          #this just sets to 1 day  \n    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs\nI’ve installed all the software you will need so just copy and paste the path I provide as given and it’ll work (lmk if its prevented by permissions or anything)\nThe first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can’t write “U” so every call will say “T” instead but it means uracil.\nFor any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I’ve spent hours before looking at why my code wont run to find out this is why\nThe following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX). Just copy paste this chunk after the sbatch part but before the dorado script.\n        module load GCC\n        module load PyTorch\n        module load FlexiBLAS/3.3.1-GCC-12.3.0  \n        module load FFmpeg/4.4.2-GCCcore-11.3.0 \n        module load HTSlib\n        module load protobuf\n\n        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too\nTo run dorado youll follow this formatting for reference, adding “\\” to the end of the line tells your system that the command isn’t done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.\n#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado\" \\ \n        basecaller \\ \n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/\" \\\n        --min-qscore 10 \\\n        --emit-fastq &gt; \"/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq\"  \nif you ever chose to do modifications then u have to remove the “–emit-fastq” tag and change the output to be a “.bam”, as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.\nI prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the “&gt;” as it says redirect this entire command into this output.\nA qscore of 10 only keeps calls &gt;=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.\nThe next step is minimap2, where you take the fastq output and align it to your reference. I’ll attach the path for the human transcriptome/genome, but I don’t have the viral reference.\n                        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2\" \\\n        -ax splice -uf -k14 -y --secondary=no \\     #keep these settings. its importnat\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa\" \\ #this is your ref file (MUST BE .fasta or .fa) \n        \"/this/is/your/dorado/output/that/your/mapping.fastq\" &gt; \"               \"/this/is/your/output/alignedsplice.sam    \nIf you would rather use the transcriptome I’ll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it path : “/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa”\nThe output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant).\nNext step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).\noutput goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters. output must be .bam and input is the .sam\n        samtools sort -o \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\" \"/This/is/input/alignedsplice.sam\" \n\n        samtools flagstat  \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\"  \nFlagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you’ll need comparing the viral reference to using genome or transcriptome."
  },
  {
    "objectID": "scripts/old_workflow.html#this-is-copy-pasted-from-my-script-but-theres-only-like-3-parts-youll-need-to-change-ive-already-combined-the-deseq2-and-volcano-plot-step-into-one-so-you-should-only-have-to-update-the-parts-of-the-following-code-that-ive-commented.",
    "href": "scripts/old_workflow.html#this-is-copy-pasted-from-my-script-but-theres-only-like-3-parts-youll-need-to-change-ive-already-combined-the-deseq2-and-volcano-plot-step-into-one-so-you-should-only-have-to-update-the-parts-of-the-following-code-that-ive-commented.",
    "title": "old_workflow",
    "section": "This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I’ve commented.",
    "text": "This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I’ve commented.\n    library(txdbmaker)\n    library(GenomicFeatures)\n    \n#*GTF file with annotated transcripts/regions*\n  \n    txdb &lt;- makeTxDbFromGFF(\"gencode.v47.annotation.gtf\")\n\n    k &lt;- keys(txdb, keytype = \"TXNAME\")  # make sure keytype exists\n    tx2gene &lt;- AnnotationDbi::select(txdb, keys = k, columns = \"GENEID\", keytype = \"TXNAME\")\nmetadata is just sample and condition listed in “ format”\n    library(tidyverse)\n    metadata &lt;- read_delim(\"metadata.txt\", delim = \"\\t\", \n                       escape_double = FALSE, trim_ws = TRUE)\n\n\n    setwd(\"C:/Users/gjand/Downloads/Schroeder_Lab/data/salmonm6a\")\n    files &lt;- paste(metadata$run, \"/quant.sf\", sep = \"\")\n    library(tximport)\n    txi &lt;- tximport(files, type = \"salmon\", tx2gene = tx2gene, txOut = F, ignoreAfterBar = T)\n\n    txi$counts |&gt; head()\n\n\n\n    library(DESeq2)\n    metadata$individual &lt;- as.factor(metadata$individual)\n\n    #  prepare deseq object\n    dds &lt;- DESeqDataSetFromTximport(txi = txi, colData = metadata, \n                                design = ~individual + condition)\n\n    dds &lt;- DESeq(dds, parallel = T)\n\n\n    # non batch corrected PCA\n    vsd &lt;- rlog(dds, blind = F)\n    pca_data &lt;- plotPCA(vsd, intgroup = c(\"condition\", \"individual\"), returnData = TRUE)\n    percentVar &lt;- round(100 * attr(pca_data, \"percentVar\"))\n    library(cowplot)\n    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +\n      geom_point(size = 3) +\n      xlab(paste0(\"PC1: \", percentVar[1], \"% variance\")) +\n      ylab(paste0(\"PC2: \", percentVar[2], \"% variance\")) +\n      ggtitle(\"Principal Component Analysis\") +\n     # scale_color_manual(values = c(\"black\", \"gray65\", \"darkblue\", \"cadetblue3\", \"springgreen4\", \"springgreen2\")) +\n      theme(aspect.ratio = 1) +\n      theme_cowplot(24) \n    # stat_ellipse(aes(group = Condition), type = \"t\", level = 0.65)\n\n    # ggsave(plot = last_plot(),\n    #        \"/name/of/save/output/path.png\",\n    #        width = 12, height = 9, units = \"in\", dpi =300, bg = \"white\")\n########################\nPCA to measure correlation between samples (need to remove batch-effect from individuals so that condition is the main difference)\n        # Batch corrected PCA\n    vsd &lt;- rlog(dds, blind = F)\n    assay(vsd) &lt;- limma::removeBatchEffect(assay(vsd), vsd$individual)\n    pca_data &lt;- plotPCA(vsd, intgroup = c(\"condition\", \"individual\"), returnData = TRUE)\n    percentVar &lt;- round(100 * attr(pca_data, \"percentVar\"))\n\n    # Custom PCA plot\n    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +\n      geom_point(size = 6) +\n      xlab(paste0(\"PC1: \", percentVar[1], \"% variance\")) +\n      ylab(paste0(\"PC2: \", percentVar[2], \"% variance\")) +\n      ggtitle(\"Principal Component Analysis\") +\n      theme(aspect.ratio = 1) +\n      theme_cowplot(24) +\n      stat_ellipse(type = \"t\", level = 0.95)\n\n    # ggsave(plot = last_plot(),\n    #        \"/name/of/save/output/path.png\",\n    #        width = 12, height = 9, units = \"in\", dpi =300, bg = \"white\")\n\n    library(org.Hs.eg.db)\n\n    mapping &lt;- AnnotationDbi::select(org.Hs.eg.db, keys = keys(org.Hs.eg.db),\n                                 columns = c(\"GENENAME\", \"ENSEMBL\", \"SYMBOL\", \"REFSEQ\"))\n\n\n    library(biomaRt)\n    mart &lt;- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n\n    # biomaRt can sometimes handle versioned IDs directly\n    listAttributes(mart) -&gt;atts\n\n    mapping &lt;- getBM(attributes=c(\"ensembl_gene_id\", \"ensembl_gene_id_version\", \"external_gene_name\",\n                              \"description\"),\n                 filters=\"ensembl_gene_id_version\",\n               values=tx2gene$GENEID,\n                 mart=mart)\n\n\n\n    # get differential eaxpression results data frame\n    res_df &lt;- results(dds, contrast = c(\"condition\", \"smoke\", \"ctrl\"), tidy = T)\n\n    res_df_ann &lt;- res_df %&gt;%\n      left_join(., mapping, by = c(\"row\" = \"ensembl_gene_id_version\"))\n\n\n    library(EnhancedVolcano)\n    EnhancedVolcano(res_df_ann,\n                lab = res_df_ann$external_gene_name,\n                x = 'log2FoldChange',\n                y = 'padj',\n                pointSize = 2\n                )\n    # \n\n        cat(\"All steps completed.\\n\")"
  }
]