[
  {
    "objectID": "scripts.html",
    "href": "scripts.html",
    "title": "Scripts",
    "section": "",
    "text": "Collection of scripts I’ve written:\n\n\nOld Workflow\nPreprocessing on RNA002 (old) chemistry data using UNIX\nView\n\n\nModkit Analysis\nR script for modkit analysis pipeline\nView\n\n\nGenome Assembly\nBash script to assemble genome both De Novo & Reference-Based\nView\n\n\nSubstitution Plot Bash & R scripts to produce accuracy of basecaller plot\nView Main Script | View Helper Script"
  },
  {
    "objectID": "scripts/old_workflow.html",
    "href": "scripts/old_workflow.html",
    "title": "old_workflow",
    "section": "",
    "text": "full start to finish workflow for basecalling and minimapping for rna002 data designed for OSCER supercomputer, ignore batch script/slurm parts for local/others\n\n\n    #!/bin/bash\n    #SBATCH --partition=rnafold                       #where it runs (use \"rnafold\" or \"normal\")\n    #SBATCH --job-name=12samples_dorado                     #name your job \n    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename\n    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name\n    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do \"gpus-per-node=1\" \n    #SBATCH --time=24:00:00          #this just sets to 1 day  \n    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs\nI’ve installed all the software you will need so just copy and paste the path I provide as given and it’ll work (lmk if its prevented by permissions or anything)\nThe first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can’t write “U” so every call will say “T” instead but it means uracil.\nFor any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I’ve spent hours before looking at why my code wont run to find out this is why\nThe following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX). Just copy paste this chunk after the sbatch part but before the dorado script.\n        module load GCC\n        module load PyTorch\n        module load FlexiBLAS/3.3.1-GCC-12.3.0  \n        module load FFmpeg/4.4.2-GCCcore-11.3.0 \n        module load HTSlib\n        module load protobuf\n\n        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too\nTo run dorado youll follow this formatting for reference, adding “\\” to the end of the line tells your system that the command isn’t done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.\n#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado\" \\ \n        basecaller \\ \n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/\" \\\n        --min-qscore 10 \\\n        --emit-fastq &gt; \"/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq\"  \nif you ever chose to do modifications then u have to remove the “–emit-fastq” tag and change the output to be a “.bam”, as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.\nI prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the “&gt;” as it says redirect this entire command into this output.\nA qscore of 10 only keeps calls &gt;=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.\nThe next step is minimap2, where you take the fastq output and align it to your reference. I’ll attach the path for the human transcriptome/genome, but I don’t have the viral reference.\n                        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2\" \\\n        -ax splice -uf -k14 -y --secondary=no \\     #keep these settings. its importnat\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa\" \\ #this is your ref file (MUST BE .fasta or .fa) \n        \"/this/is/your/dorado/output/that/your/mapping.fastq\" &gt; \"               \"/this/is/your/output/alignedsplice.sam    \nIf you would rather use the transcriptome I’ll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it path : “/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa”\nThe output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant).\nNext step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).\noutput goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters. output must be .bam and input is the .sam\n        samtools sort -o \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\" \"/This/is/input/alignedsplice.sam\" \n\n        samtools flagstat  \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\"  \nFlagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you’ll need comparing the viral reference to using genome or transcriptome."
  },
  {
    "objectID": "scripts/old_workflow.html#beginning-batch-script-to-run-on-slurm",
    "href": "scripts/old_workflow.html#beginning-batch-script-to-run-on-slurm",
    "title": "old_workflow",
    "section": "",
    "text": "#!/bin/bash\n    #SBATCH --partition=rnafold                       #where it runs (use \"rnafold\" or \"normal\")\n    #SBATCH --job-name=12samples_dorado                     #name your job \n    #SBATCH --output=dorado1_ALLSAMPLES_output.txt              #keep _output at end but rename\n    #SBATCH --error=dorado1_ALLSAMPLES_debug.txt          #keep _debug at end but u can change name\n    #SBATCH --cpus-per-task=2   #use as written. if u need more power/gpu then do \"gpus-per-node=1\" \n    #SBATCH --time=24:00:00          #this just sets to 1 day  \n    #SBATCH --mem=16G               #rn its set to 16gb, i rarely go above 32gb for big jobs\nI’ve installed all the software you will need so just copy and paste the path I provide as given and it’ll work (lmk if its prevented by permissions or anything)\nThe first step is to run dorado to basecall your data (takes fast5 and reads as A,C,T,G). The software can’t write “U” so every call will say “T” instead but it means uracil.\nFor any script youll add that sbatch to top, MAKING SURE that #!/bin/bash is on line 1. I’ve spent hours before looking at why my code wont run to find out this is why\nThe following modules need to be loaded to run dorado, these are dependencies that are kinda like R packages you would load in (but in UNIX). Just copy paste this chunk after the sbatch part but before the dorado script.\n        module load GCC\n        module load PyTorch\n        module load FlexiBLAS/3.3.1-GCC-12.3.0  \n        module load FFmpeg/4.4.2-GCCcore-11.3.0 \n        module load HTSlib\n        module load protobuf\n\n        module load SAMtools/1.16.1-GCC-11.3.0 #this ones for minimap but add here too\nTo run dorado youll follow this formatting for reference, adding “\\” to the end of the line tells your system that the command isn’t done being written yet. So basically if you have extra spaces or anything other than this specific thing at the end of the line, your code wont work. So for every command I only add 1 space between and change lines by pressing enter only.\n#theres a slight chance that youre gonna get an error about formatting, if so its because the model needs to be placed somewhere else, just chatgpt the chunk of code and your error and you should be able to debug it.\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-    linux-x64/bin/dorado\" \\ \n        basecaller \\ \n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/dorado-0.8.2/dorado-0.8.2-linux-x64/models/rna002_70bps_hac@v3/\" \\\n        --min-qscore 10 \\\n        --emit-fastq &gt; \"/ADDYOURUSERHERE/ANDOUTPUT/PATH.fastq\"  \nif you ever chose to do modifications then u have to remove the “–emit-fastq” tag and change the output to be a “.bam”, as fastq cant carry the mod data over. Theres a couple more fancy steps to this so lmk if you decide to do mods.\nI prefer to use absolute paths because its way easier to see where the outputs going. make sure to have the “&gt;” as it says redirect this entire command into this output.\nA qscore of 10 only keeps calls &gt;=90% calls, can reduce to ~6-8 if it significantly reduces your data amount.\nThe next step is minimap2, where you take the fastq output and align it to your reference. I’ll attach the path for the human transcriptome/genome, but I don’t have the viral reference.\n                        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/software/marginAlign/submodules/minimap2/minimap2\" \\\n        -ax splice -uf -k14 -y --secondary=no \\     #keep these settings. its importnat\n        \"/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/GRCh38.fa\" \\ #this is your ref file (MUST BE .fasta or .fa) \n        \"/this/is/your/dorado/output/that/your/mapping.fastq\" &gt; \"               \"/this/is/your/output/alignedsplice.sam    \nIf you would rather use the transcriptome I’ll attach the path to the updated version, just replace the genome part with it. its already been indexed too but if needed ever just do samtools index before any .fa to index it path : “/ourdisk/hpc/rnafold/gjandebeur/dont_archive/reference/gencode.v47.transcripts.fa”\nThe output has to stay .sam but u can change the name to whatever, I prefer naming it alignedsplice to show that its aligned and has splice variants (just improves mapping slightly but unimportant).\nNext step you have to sort your reads, just makes it easier for the computer to understand and converts format to a computer-readable one only (bam).\noutput goes first in this (the -o flag), and just add the input directly on end with only a space after the output, no other characters. output must be .bam and input is the .sam\n        samtools sort -o \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\" \"/This/is/input/alignedsplice.sam\" \n\n        samtools flagstat  \"/THIS/IS/OUTPUT/FIRST/SORTED.BAM\"  \nFlagstat shows the stats that you want! (total aligned #, mapped #, and map %). This is the info I think you’ll need comparing the viral reference to using genome or transcriptome."
  },
  {
    "objectID": "scripts/old_workflow.html#this-is-copy-pasted-from-my-script-but-theres-only-like-3-parts-youll-need-to-change-ive-already-combined-the-deseq2-and-volcano-plot-step-into-one-so-you-should-only-have-to-update-the-parts-of-the-following-code-that-ive-commented.",
    "href": "scripts/old_workflow.html#this-is-copy-pasted-from-my-script-but-theres-only-like-3-parts-youll-need-to-change-ive-already-combined-the-deseq2-and-volcano-plot-step-into-one-so-you-should-only-have-to-update-the-parts-of-the-following-code-that-ive-commented.",
    "title": "old_workflow",
    "section": "This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I’ve commented.",
    "text": "This is copy pasted from my script but theres only like 3 parts youll need to change, ive already combined the DEseq2 and volcano plot step into one so you should only have to update the parts of the following code that I’ve commented.\n    library(txdbmaker)\n    library(GenomicFeatures)\n    \n#*GTF file with annotated transcripts/regions*\n  \n    txdb &lt;- makeTxDbFromGFF(\"gencode.v47.annotation.gtf\")\n\n    k &lt;- keys(txdb, keytype = \"TXNAME\")  # make sure keytype exists\n    tx2gene &lt;- AnnotationDbi::select(txdb, keys = k, columns = \"GENEID\", keytype = \"TXNAME\")\nmetadata is just sample and condition listed in “ format”\n    library(tidyverse)\n    metadata &lt;- read_delim(\"metadata.txt\", delim = \"\\t\", \n                       escape_double = FALSE, trim_ws = TRUE)\n\n\n    setwd(\"C:/Users/gjand/Downloads/Schroeder_Lab/data/salmonm6a\")\n    files &lt;- paste(metadata$run, \"/quant.sf\", sep = \"\")\n    library(tximport)\n    txi &lt;- tximport(files, type = \"salmon\", tx2gene = tx2gene, txOut = F, ignoreAfterBar = T)\n\n    txi$counts |&gt; head()\n\n\n\n    library(DESeq2)\n    metadata$individual &lt;- as.factor(metadata$individual)\n\n    #  prepare deseq object\n    dds &lt;- DESeqDataSetFromTximport(txi = txi, colData = metadata, \n                                design = ~individual + condition)\n\n    dds &lt;- DESeq(dds, parallel = T)\n\n\n    # non batch corrected PCA\n    vsd &lt;- rlog(dds, blind = F)\n    pca_data &lt;- plotPCA(vsd, intgroup = c(\"condition\", \"individual\"), returnData = TRUE)\n    percentVar &lt;- round(100 * attr(pca_data, \"percentVar\"))\n    library(cowplot)\n    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +\n      geom_point(size = 3) +\n      xlab(paste0(\"PC1: \", percentVar[1], \"% variance\")) +\n      ylab(paste0(\"PC2: \", percentVar[2], \"% variance\")) +\n      ggtitle(\"Principal Component Analysis\") +\n     # scale_color_manual(values = c(\"black\", \"gray65\", \"darkblue\", \"cadetblue3\", \"springgreen4\", \"springgreen2\")) +\n      theme(aspect.ratio = 1) +\n      theme_cowplot(24) \n    # stat_ellipse(aes(group = Condition), type = \"t\", level = 0.65)\n\n    # ggsave(plot = last_plot(),\n    #        \"/name/of/save/output/path.png\",\n    #        width = 12, height = 9, units = \"in\", dpi =300, bg = \"white\")\n########################\nPCA to measure correlation between samples (need to remove batch-effect from individuals so that condition is the main difference)\n        # Batch corrected PCA\n    vsd &lt;- rlog(dds, blind = F)\n    assay(vsd) &lt;- limma::removeBatchEffect(assay(vsd), vsd$individual)\n    pca_data &lt;- plotPCA(vsd, intgroup = c(\"condition\", \"individual\"), returnData = TRUE)\n    percentVar &lt;- round(100 * attr(pca_data, \"percentVar\"))\n\n    # Custom PCA plot\n    ggplot(pca_data, aes(x = PC1, y = PC2, color = condition, shape = individual)) +\n      geom_point(size = 6) +\n      xlab(paste0(\"PC1: \", percentVar[1], \"% variance\")) +\n      ylab(paste0(\"PC2: \", percentVar[2], \"% variance\")) +\n      ggtitle(\"Principal Component Analysis\") +\n      theme(aspect.ratio = 1) +\n      theme_cowplot(24) +\n      stat_ellipse(type = \"t\", level = 0.95)\n\n    # ggsave(plot = last_plot(),\n    #        \"/name/of/save/output/path.png\",\n    #        width = 12, height = 9, units = \"in\", dpi =300, bg = \"white\")\n\n    library(org.Hs.eg.db)\n\n    mapping &lt;- AnnotationDbi::select(org.Hs.eg.db, keys = keys(org.Hs.eg.db),\n                                 columns = c(\"GENENAME\", \"ENSEMBL\", \"SYMBOL\", \"REFSEQ\"))\n\n\n    library(biomaRt)\n    mart &lt;- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n\n    # biomaRt can sometimes handle versioned IDs directly\n    listAttributes(mart) -&gt;atts\n\n    mapping &lt;- getBM(attributes=c(\"ensembl_gene_id\", \"ensembl_gene_id_version\", \"external_gene_name\",\n                              \"description\"),\n                 filters=\"ensembl_gene_id_version\",\n               values=tx2gene$GENEID,\n                 mart=mart)\n\n\n\n    # get differential eaxpression results data frame\n    res_df &lt;- results(dds, contrast = c(\"condition\", \"smoke\", \"ctrl\"), tidy = T)\n\n    res_df_ann &lt;- res_df %&gt;%\n      left_join(., mapping, by = c(\"row\" = \"ensembl_gene_id_version\"))\n\n\n    library(EnhancedVolcano)\n    EnhancedVolcano(res_df_ann,\n                lab = res_df_ann$external_gene_name,\n                x = 'log2FoldChange',\n                y = 'padj',\n                pointSize = 2\n                )\n    # \n\n        cat(\"All steps completed.\\n\")"
  },
  {
    "objectID": "scripts/genome_assembly.html",
    "href": "scripts/genome_assembly.html",
    "title": "genome_assembly",
    "section": "",
    "text": "full pipeline for genome assembly (de novo & reference-based)\nlibrary prep for assembly (fastQC, fastp/fastplong, minimap2/flye)\n\n\nfor loop to perform fastQC\nfor file in /example/directory/*.fastq.gz\ndo\n    fastqc \"$file\" --threads 8 --outdir /example/output/fastQC/\ndone\n\n\n\nfor file in /example/directory/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    fastplong \\\n          -i \"$file\" \\\n          -o \"/example/output/$sample_trim.fastq.gz\" \\\n          --disable_adapter_trimming \\\n          -q 15 -l 30 -n 0 \\\n          --cut_front --cut_tail -M 20 -W 4 \\\n          --trim_poly_x \\\n          --json \"/output/${sample}_fastplong.json\" \\\n          --html \"/output/${sample}_fastplong.html\" \\\n          --thread 8 \n\n    echo \"$sample finished\"\ndone\n\n\n\nfor file in /example/rawdata/directory/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    sample=${fname%_R1_001.fastq.gz}\n    \n    r1_file=\"/example/file/one.fastq.gz\"\n    r2_file=\"/example/file/two.fastq.gz\"\n    \n    if [[ -f \"$r1_file\" && -f \"$r2_file\" ]]; then\n        echo \"Processing sample: $sample\"    \n        fastp \\\n              --in1 \"$r1_file\" \\\n              --in2 \"$r2_file\" \\\n              --out1 \"/example/output/one_clean.fastq.gz\" \\\n              --out2 \"/example/output/two_clean.fastq.gz\"  \\\n              --unpaired1 example/one.unpaired.fastq \\\n              --unpaired2 example/two.unpaired.fastq \\\n              --failed_out /example/failedreads/$sample.fastq \\\n              -q 30 -l 100 -n 2 -e 30 --cut_front --cut_tail -M 30 -W 1 \\\n              --trim_poly_g \\\n              --trim_poly_x \\\n              --dont_eval_duplication \\\n              --json \"/example/report/${sample}_fastp.json\" \\\n              --html \"/example/report/${sample}_fastp.html\" \\\n              --thread 8 \\\n    else\n        echo \"Warning: Missing R1 or R2 file for sample $sample\"\n    fi\ndone\nin1 and in2 == input files out1 and out2 == output files unpaired 1/2 == reads that didn’t fit both in1 and in2 failed == couldn’t read -q (Phred q score) -l 100 == minimum length of read to be counted -n 2 == at MAX 2 N reads (unknown nucleotide) per read without being disgarded –cut_front / cut_tail == cut out first nucleotides/adapter -M 30 == cuts above only if phred score &gt; 30. -W 1 == reading window of one, reads one nucleotide at a time –trim_poly_g / trim_poly_x == trim out polyG/polyX tails that may occur –dont_eval_duplication == doesn’t look for duplications to save memory (This was already done in fastQC/MultiQC steps)\n\n\n\nSame code as prior just change the input/outputs\n\n\n\nmultiqc -n illumina_multiqc -d /example/fastQC/fastp_data/\nmultiqc -n nanopore_multiqc -d /example/fastQC/fastplong_data/\n-n == the output files name -d == the input directory\n\n\n\n\n\n\nuse Flye program (install via conda/bioconda)\nfor file in /example/fastplong/data/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    flye --nano-hq \"$file\" \\\n        -g 12.3m \\\n        -o \"/scratch/gjandebeur/Cglabrata/flye/postfilter/${fname%}_nanopore.fastq\" \\\n        --threads 8\ndone\nOptions for FLYE include: -g == genome size expected (~12.3m for C. glabrata) -o == output file –threads (how many CPU you have listed)\n\n\nFirst for ONT data\n#for file in /example/rawdata/*fastq.gz\n#do\n#    if [ -f \"$file\" ]; then\n#    fname=$(basename \"$file\" .fastq.gz)\n#    echo \"Processing $fname...\"\n#    \n#    ./minimap2 -ax map-ont \\\n#    \"/REFERENCE/FILE.fasta\" \\\n#    \"$file\" &gt; /output/ONT/${fname}.sam\n#    fi\n#      echo \"minimap2 failed\"\n#done\nfor above; -ax map-ont == uses ONT mapping to genome\nNext minimap2 for Illumina paired reads (different syntax)\n#for file1 in \"/example/file2/illumina/*_R1_001*.fastq.gz\n#do\n#    if [ -f \"$file1\" ]; then\n#        base=\"${file1%_R1_001*.fastq.gz}\"\n#        base=$(basename \"$base\")\n#        file2=\"/example/file2/illumina/${base}_R2_001*.fastq.gz\"\n#        file2=$(ls $file2 2&gt;/dev/null | head -1)\n#        if [ -f \"$file2\" ]; then\n#            echo \"Processing paired files for sample: $base\"\n#            echo \"R1: $(basename $file1)\"\n#            echo \"R2: $(basename $file2)\"\n#            ./minimap -ax sr \\\n#            \"/REFERENCE/FILE.fasta\" \\\n#            \"$file1\" \"$file2\" &gt; /output/illumina/${base}.sam\n#            echo \"Generated: ${base}.sam\"\n#        else\n#            echo \"Warning: R2 file not found for $file1\"\n#            echo \"Expected: $file2\"\n#        fi\n#        echo \"---------------------------------------------\"\n#    fi\n#done\nfor above; -ax sr === mapping using paired reads (illumina) both file1/file2 must be paired data (not just two similar files)\n\n\nfor file in /example/input/from/minimap2/*.sam\ndo\n    fname=$(basename \"$file\" .sam)\n    bam=\"/example/output/filepath/bam/${fname}.bam\"\n    echo \"Converting $file to sorted BAM...\"\n    \n    # Add temp directory and memory limit\n    samtools sort -T /example/temporarydirectory/forsorting/tmp/${fname} -m 2G -o \"$bam\" \"$file\" || { echo \"Sort failed for $file\"; continue; }\n    \n    samtools index \"$bam\"\n    samtools flagstat \"$bam\"\n    echo \"Done with $fname.\"\n    echo \"---------------------------------------------\"\ndone\nfor file in /example/alldata/postfilter/*.bam\ndo\n  samtools flagstat\necho \"----------------------------------------------------\"\n\ndone\nAfter obtaining output files with the flagstat data, as well as from the Flye assembly, you can run the code attached to this directory to pull out statistical data and place into a .xlsx file for further analyses. THESE TWO FILES MENTIONED ABOVE MUST BE RUN AS PYTHON SCRIPTS\nNow Run BCFtools to mpileup reads\nref_dir=\"/pathto/reference\"\nbam_dir=\"/path/to/postfilter/ONT/bam\"\noutput_dir=\"/path/to/output/postfilter/bcfpileup/\"  \n\necho \"Starting bcf mpileup loop\"\n\nfor bam_file in \"$bam_dir\"/*.bam\ndo\n    if [ -f \"$bam_file\" ]; then\n        sample=$(basename \"$bam_file\" .bam)\n        output_file=\"$output_dir/${sample}.vcf.gz\"\n        \n        # Skip if output file already exists\n        if [ -f \"$output_file\" ]; then\n            echo \"Skipping $sample - output already exists: $output_file\"\n            continue\n        fi\n        \n        echo \"Processing sample: $sample\"\n        echo \"BAM file: $bam_file\"\n        \n        bcftools mpileup \\\n            --max-depth 1000000 \\\n            --threads 8 \\\n            -O z \\\n            -o \"$output_file\" \\\n            -f \"$ref_dir/referencefile.fasta\" \\\n            \"$bam_file\"\n        \n        echo \"Generated: ${sample}.vcf.gz\"\n        echo \"---------------------------------------------\"\n    fi\ndone\necho \"bcftools mpileup loop completed.\"\nUsing the pileup files, run bcftools call for SNP analysis"
  },
  {
    "objectID": "scripts/genome_assembly.html#to-perform-de-novo-assembly-of-genome-must-be-on-ont-data",
    "href": "scripts/genome_assembly.html#to-perform-de-novo-assembly-of-genome-must-be-on-ont-data",
    "title": "genome_assembly",
    "section": "",
    "text": "use Flye program (install via conda/bioconda)\nfor file in /example/fastplong/data/*.fastq.gz\ndo\n    fname=$(basename \"$file\")\n    \n    flye --nano-hq \"$file\" \\\n        -g 12.3m \\\n        -o \"/scratch/gjandebeur/Cglabrata/flye/postfilter/${fname%}_nanopore.fastq\" \\\n        --threads 8\ndone\nOptions for FLYE include: -g == genome size expected (~12.3m for C. glabrata) -o == output file –threads (how many CPU you have listed)\n\n\nFirst for ONT data\n#for file in /example/rawdata/*fastq.gz\n#do\n#    if [ -f \"$file\" ]; then\n#    fname=$(basename \"$file\" .fastq.gz)\n#    echo \"Processing $fname...\"\n#    \n#    ./minimap2 -ax map-ont \\\n#    \"/REFERENCE/FILE.fasta\" \\\n#    \"$file\" &gt; /output/ONT/${fname}.sam\n#    fi\n#      echo \"minimap2 failed\"\n#done\nfor above; -ax map-ont == uses ONT mapping to genome\nNext minimap2 for Illumina paired reads (different syntax)\n#for file1 in \"/example/file2/illumina/*_R1_001*.fastq.gz\n#do\n#    if [ -f \"$file1\" ]; then\n#        base=\"${file1%_R1_001*.fastq.gz}\"\n#        base=$(basename \"$base\")\n#        file2=\"/example/file2/illumina/${base}_R2_001*.fastq.gz\"\n#        file2=$(ls $file2 2&gt;/dev/null | head -1)\n#        if [ -f \"$file2\" ]; then\n#            echo \"Processing paired files for sample: $base\"\n#            echo \"R1: $(basename $file1)\"\n#            echo \"R2: $(basename $file2)\"\n#            ./minimap -ax sr \\\n#            \"/REFERENCE/FILE.fasta\" \\\n#            \"$file1\" \"$file2\" &gt; /output/illumina/${base}.sam\n#            echo \"Generated: ${base}.sam\"\n#        else\n#            echo \"Warning: R2 file not found for $file1\"\n#            echo \"Expected: $file2\"\n#        fi\n#        echo \"---------------------------------------------\"\n#    fi\n#done\nfor above; -ax sr === mapping using paired reads (illumina) both file1/file2 must be paired data (not just two similar files)\n\n\nfor file in /example/input/from/minimap2/*.sam\ndo\n    fname=$(basename \"$file\" .sam)\n    bam=\"/example/output/filepath/bam/${fname}.bam\"\n    echo \"Converting $file to sorted BAM...\"\n    \n    # Add temp directory and memory limit\n    samtools sort -T /example/temporarydirectory/forsorting/tmp/${fname} -m 2G -o \"$bam\" \"$file\" || { echo \"Sort failed for $file\"; continue; }\n    \n    samtools index \"$bam\"\n    samtools flagstat \"$bam\"\n    echo \"Done with $fname.\"\n    echo \"---------------------------------------------\"\ndone\nfor file in /example/alldata/postfilter/*.bam\ndo\n  samtools flagstat\necho \"----------------------------------------------------\"\n\ndone\nAfter obtaining output files with the flagstat data, as well as from the Flye assembly, you can run the code attached to this directory to pull out statistical data and place into a .xlsx file for further analyses. THESE TWO FILES MENTIONED ABOVE MUST BE RUN AS PYTHON SCRIPTS\nNow Run BCFtools to mpileup reads\nref_dir=\"/pathto/reference\"\nbam_dir=\"/path/to/postfilter/ONT/bam\"\noutput_dir=\"/path/to/output/postfilter/bcfpileup/\"  \n\necho \"Starting bcf mpileup loop\"\n\nfor bam_file in \"$bam_dir\"/*.bam\ndo\n    if [ -f \"$bam_file\" ]; then\n        sample=$(basename \"$bam_file\" .bam)\n        output_file=\"$output_dir/${sample}.vcf.gz\"\n        \n        # Skip if output file already exists\n        if [ -f \"$output_file\" ]; then\n            echo \"Skipping $sample - output already exists: $output_file\"\n            continue\n        fi\n        \n        echo \"Processing sample: $sample\"\n        echo \"BAM file: $bam_file\"\n        \n        bcftools mpileup \\\n            --max-depth 1000000 \\\n            --threads 8 \\\n            -O z \\\n            -o \"$output_file\" \\\n            -f \"$ref_dir/referencefile.fasta\" \\\n            \"$bam_file\"\n        \n        echo \"Generated: ${sample}.vcf.gz\"\n        echo \"---------------------------------------------\"\n    fi\ndone\necho \"bcftools mpileup loop completed.\"\nUsing the pileup files, run bcftools call for SNP analysis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gjandebeur’s Github",
    "section": "",
    "text": "Current PhD Student at OUHSC interested in computational biology and bioinformatics"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "scripts/Accuracy_Substitution_Plot.html",
    "href": "scripts/Accuracy_Substitution_Plot.html",
    "title": "Accuracy_Substitution_Plot",
    "section": "",
    "text": "Substitutionplot\nFull Pipeline to produce a plot showing accuracy of basecaller reads compared to reference.\nCreates the following graph \nUses multiple programs, will show full input/output to get to the graph\nFirst, run Dorado on the pod5/fast5 raw reads to produce a sam file\n./dorado \\\nbasecaller \\\n--models-directory /directory/to_location_of/dorado-1.0.1-linux-x64/rna004_130bps_sup@v5.2.0/ \\\nsup,inosine_m6A_2OmeA,2OmeG,m5C_2OmeC,pseU_2OmeU \\ #this will investigate all 8 mods currently available as of Dorado 1.0.1\n--min-qscore 10 \\ #min score removes bottom 90% of reads\n--emit-moves \\ #doesn't keep the eventalign files (unneeded and saves LOTS of space/memory)\n--estimate-poly-a \\ #adds polyA information to file for downstream processing\n-r \"/inputfile/location/pod5/\" \\\n&gt; \"/example/output/*_basecalled.bam\"\nUse this output to align to genome using Minimap2\nsamples=(\"list samples here\")\n\n# Paths\nminimap2=\"/path/to/minimap2\nref=\"/reference/file/*.transcripts.fa\"\nrawdir=\"/path/to/rawdata\"\nprocdir=\"/output/directory/for/processed_data/\"\n\n# Loop over each sample\nfor sample in \"${samples[@]}\"; do\n    echo \"Processing $sample...\"\n\n    fastq=\"${rawdir}/${sample}_8mod_basecalled.fastq\"\n    sam=\"${rawdir}/${sample}_8mod_aligned_splice.sam\"   #splice because we use -ax splice instead of -ax map-ont (seems to slightly improve the accuracy)\n    bam=\"${procdir}/${sample}_8mod_aligned_sortedsplice.bam\"\n\n    # Align with minimap2\n    \"$minimap2\" -ax splice -uf -k14 -y --secondary=no \"$ref\" \"$fastq\" &gt; \"$sam\"\n\n    # Convert to sorted BAM\n    samtools sort -o \"$bam\" \"$sam\"\n\n    # Get alignment stats\n    samtools flagstat \"$bam\"\n\n    echo \"Done with $sample.\"\n    echo \"---------------------------------------------\"\ndone\nImportant options -ax splice == spliced mapping [better for RNA] -uf -k14 == best options for noisy mRNA reads –secondary==no == removes secondary reads\n\nNext is MarginAlign/MarginStats, run on Python2.7.15 (old old), to find these statistical values\nfirst you must “uniquify” the fastq, removing any duplicate reads\n\"/path/to/marginAlign/scripts/uniquifyFastq\" \\\n\"/input/nonprocessed/*.fastq\" \\\n\"/processed/output/*uniquify.fastq\"\nUse the uniquify output to run marginStats\n\"/path/to/marginalign/marginStats\" \\\n--localAlignment \"/path/to/prev/output.bam\" \\\n\"/path/to/the/uniquified/file/.fastq\" \\\n\"/reference/file.fa\" \\\n--readIdentity \\\n--alignmentIdentity \\\n--readCoverage \\\n--readLength \\\n--printValuePerReadAlignment &gt; \"/output/testoutput.txt\"\nTo run the plot script, we must convert .txt into .tsv and convert all T into U to represent Uracil in RNA (current BAM files only can use T (thymine))\nsed 's/  */\\t/g' \"/sample/output.txt\" &gt; \"/sample/output.tsv\"\nsed 's/T/U/g'  \"/sample/output.tsv\" &gt; \"/sample/output_subU.tsv\" \n\n\n\nBEFORE RUNNING THE RSCRIPT\n*the tsv output from above has 4 lines of stats that you must remove for the plot to work. I have no clue why it adds these here but it will throw errors if not removed.\ntail -n +5 \"/sample/output_subU.tsv\" &gt; \"/sample/output_subU_cleaned.tsv\" \nUsing the below formatting, run the script in files as an R script to create the graph (this is currently set up for SLURM on UNIX to run Rscript). -The substitutionplot.R script\nRscript substitutionplot.R \\\n\"/sample/output_subU_cleaned.tsv\" \"/output/substitutionplot.tiff\" \\\n\"Substitution Matrix for reproducibility\" #title of graph"
  },
  {
    "objectID": "scripts/Modkit_Analysis_dRNAseq.html",
    "href": "scripts/Modkit_Analysis_dRNAseq.html",
    "title": "Modkit_Analysis_dRNAseq",
    "section": "",
    "text": "dRNA_analyses\nWorkflow for analyses of m6A Modifications Post Modkit Filtering\nload dependencies first\nlibrary(data.table)\nlibrary(tidyverse) \nlibrary(tidytable)\nlibrary(patchwork)\nlibrary(ggplot2)\nlibrary(GenomicRanges)\nlibrary(txdbmaker)\nsetwd and import m6A_subset from “m6A_subset_allstats.tsv”\n\nPlot data from filtered file, coverage & percent modified\nThis can and should be scaled up with more modification types and samples\nggplot(m6A_subset, aes(x = avg_n_valid_cov, y = avg_percent_modified, color = mod)) +\n  geom_smooth(method = \"gam\", formula = y ~ s(x, bs = \"cs\"), se = FALSE, linewidth = 1.2) +\n  scale_x_log10(limits = c(10, 10000)) +\n  scale_color_brewer(palette = \"Set1\") +\n  labs(\n    x = \"Valid Coverage (log10)\",\n    y = \"Percent Modified\",\n    color = \"Modification\",\n    title = \"Coverage and Percent Modification\"\n  ) +\n  theme_classic(base_size = 14)\n\nload in txdb from gtf file (provided in files)\ntxdb &lt;- makeTxDbFromGFF(\"at_ensembl_plants.gtf\")\nk &lt;- keys(txdb, keytype = \"TXNAME\")  \ntx2gene_at &lt;- AnnotationDbi::select(txdb, keys = k, columns = \"GENEID\", keytype = \"TXNAME\")\nintersect txdb with the m6A_subset dataframe\n#intersecting files\nm6A_subset &lt;- m6A_subset %&gt;%\n  inner_join(., tx2gene_at, by=c(\"tx\"= \"TXNAME\")) %&gt;%\n  unite(position, chrom:end, remove =F) \n\n#changing format to make reproducible\nm6A_subset &lt;- m6A_subset %&gt;%\n  separate(position, into = c(\"chrom\", \"start\", \"end\"), sep = \"_\", remove = FALSE) %&gt;%\n  mutate(\n    start = as.integer(start),\n    end = as.integer(end)\n  )\n\n\nNow running Genomic Ranges to split tx into their genomic regions\nmods &lt;- GRanges(\n  seqnames = m6A_subset$chrom,\n  ranges = IRanges(start = m6A_subset$start, end = m6A_subset$end),\n  mod = m6A_subset$mod,\n  gene_id = m6A_subset$gene_id\n)\n\ncds_gr &lt;- cds(txdb)\nfive_utr_gr &lt;- fiveUTRsByTranscript(txdb, use.names = TRUE) |&gt; unlist()\nthree_utr_gr &lt;- threeUTRsByTranscript(txdb, use.names = TRUE) |&gt; unlist()\nintrons_gr &lt;- intronsByTranscript(txdb, use.names = TRUE) |&gt; unlist()\n\n\nNow running function to find each region’s hits\nassign_region &lt;- function(mods, cds, five_utr, three_utr, introns) {\n  region &lt;- rep(\"intergenic\", length(mods))  # default assignment\n\n  hits_cds &lt;- findOverlaps(mods, cds)\n  region[queryHits(hits_cds)] &lt;- \"CDS\"\n  hits_5utr &lt;- findOverlaps(mods, five_utr)\n  idx_5utr &lt;- setdiff(queryHits(hits_5utr), queryHits(hits_cds))\n  region[idx_5utr] &lt;- \"5'UTR\"  \n  hits_3utr &lt;- findOverlaps(mods, three_utr)\n  idx_3utr &lt;- setdiff(queryHits(hits_3utr), c(queryHits(hits_cds), idx_5utr))\n  region[idx_3utr] &lt;- \"3'UTR\"\n  \n  hits_introns &lt;- findOverlaps(mods, introns)\n  idx_introns &lt;- setdiff(queryHits(hits_introns), c(queryHits(hits_cds), idx_5utr, idx_3utr))\n  region[idx_introns] &lt;- \"intron\"\n  \n  return(region)\n}\n\n# add region tag to the original dataframe for downstream analyses\nm6A_subset$region &lt;- assign_region(mods_gr, cds_gr, five_utr_gr, three_utr_gr, introns_gr)\n\n#Lastly, filter by descending groups \nsummary_filtered_data_byregion &lt;-  m6A_subset %&gt;%\n  group_by(region, mod) %&gt;%\n  summarise(n_mods = n(), .groups = \"drop\") %&gt;%\n  arrange(desc(n_mods))\n\n# For overview of graph\ntable(m6A_subset$region)\n\n\nNow plotting genomic ranges\nregion_mod_summary &lt;- m6A_subset %&gt;%\n  group_by(region, mod) %&gt;%\n  summarise(n_mods = n(), .groups = \"drop\")\n\nfiltered_region_mod_summary &lt;- region_mod_summary %&gt;%\n  filter(mod %in% c(\"pseU\", \"m6A\"))\n\n#Now Actually Plot\n## This can be easily scaled up with other modification types or species\n\nggplot(filtered_region_mod_summary, aes(x = region, y = n_mods, fill = region)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \"Modification Counts per Region (pseU & m6A)\",\n    x = \"Genomic Region\",\n    y = NULL,\n    fill = \"Genomic Region\"\n  ) +\n  scale_fill_aaas() +\n  facet_wrap(~ mod, scales = \"free_y\") +\n  theme_minimal(24) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    axis.text.x = element_blank()  # this removes tick labels under bars\n  )\n\n\n\nGO Enrichment Analyses\n#First load in GO term file to produce the background\n\nbackground &lt;- read_delim(\"arabidopsis_go_terms.txt\", \ndelim = \"\\t\", escape_double = FALSE,  \ntrim_ws = TRUE) %&gt;% \ndplyr::select(3,1) %&gt;% \ndplyr::rename(term = 1, gene = 2)\n\nm6a_genes &lt;- final_filtered_data %&gt;%\n   filter(mod == \"m6A\") %&gt;%\n   distinct(gene_id)\nm6a_genes &lt;- m6a_genes %&gt;%\n  mutate(gene_id = sub(\"^gene:\", \"\", gene_id))\nego &lt;- enricher(\n  m6a_genes$gene_id,\n  pvalueCutoff = 0.05,\n  pAdjustMethod = \"BH\",\n  universe = background$gene,\n  minGSSize = 10,\n  maxGSSize = 500,\n  qvalueCutoff = 0.05,\n  gson = NULL,\n  TERM2GENE =  goterms\n  )\n\n\nhyper_ego &lt;- mutate(ego, FoldEnrichment = parse_ratio(GeneRatio) / parse_ratio(BgRatio))\n\ndotplot(hyper_ego, x=\"FoldEnrichment\") +\n  ggtitle(\"m6A modified genes\") +\n  theme_cowplot(16)\n\n\n\nNext export the subset file as bed to run bedtools intersect (must be done unix) to line up with reference file and output as fasta\nm6A_subset %&gt;%\n  filter(code == \"a\") %&gt;%\n  dplyr::select(chrom, start, end, code, n_valid_cov, strand) %&gt;%\n  distinct(chrom, start, end, .keep_all = T) %&gt;%\n  arrange(chrom, start) %&gt;%\n  mutate(start = start - 3,\n         end = end + 3) %&gt;%\n  write.table(\"C:/extract/to/bedfile.bed\",\n              col.names = F, row.names = F, sep = \"\\t\", quote = F)\n\n\nNext code can NOT be run in RStudio, must export to a UNIX shell\nThe next part must be run on Unix with bedtools installed to run the intersect on the bed file with the known fasta reference\n./bedtools getfasta -s -fi \"reference_toplevel.fa\" -bed \"C:/extract/to/bedfile.bed\" &gt; \"bedfile_nowfa.fasta\"\n\nsamtools faidx bedfile_nowfa.fasta\"\n\n\nUsing pA lengths from original basecalling for analyses\nm6A_subset_tails &lt;- m6A_subset %&gt;%\n  mutate(\n    tail_length_group = case_when(\n      mean_tail_length &lt;= quantile(mean_tail_length, 0.25, na.rm = TRUE) ~ \"short\",\n      mean_tail_length &gt;= quantile(mean_tail_length, 0.75, na.rm = TRUE) ~ \"long\",\n      TRUE ~ \"medium\"\n    )\n  )\nAfter all library prep is done can plot multiple variables against, like plotting CPM, stoich, and polyA length (This graph has no correlation due to the subset but minor trends can be viewed with biological data)\nggplot(m6A_subset, aes(x = mean_CPM, y = tail_length)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  scale_x_log10() +\n  labs(title = \"Expression vs PolyA Tail Length (All Species)\", x = \"Mean CPM (log scale)\", y = \"Mean PolyA Tail Length\") +\n  theme_minimal(base_size = 14)"
  },
  {
    "objectID": "scripts/Substitutionplot.html",
    "href": "scripts/Substitutionplot.html",
    "title": "Substitutionplot",
    "section": "",
    "text": "&lt;img width=\"1024\" height=\"1536\" alt=\"Substitution Plot Jul 9, 2025\" src=\"https://github.com/user-attachments/assets/5e0a4fbe-6812-4c3f-ae4a-617e8cf9f60a\" /&gt;\n\nargs &lt;- commandArgs(trailingOnly = TRUE)\n\nlibrary(lattice)\n\nf &lt;- args[1]\nout &lt;- args[2]\ninf &lt;- args[3]\nprint(\"beginning panel function\")\n# Custom panel function with larger font size for text\nmyPanel &lt;- function(x, y, z, ...) {\n    panel.levelplot(x, y, z, ...)\n    # Increase font size using cex argument\n    panel.text(x, y, labels = paste(100 * round(exp(-z),4), \"%\", sep=\"\"), cex = 1.5) # Adjust cex for larger font\n}\n\n\nprint(\"reading data\")\n\nd &lt;- read.table(f, header = TRUE, row.names = 1)\n\n\n\nif (dim(d)[1] &gt; 0 && sum(d) &gt; 0) {\n    \nprint(\"plotting as tiff now\")\n    # Use tiff() instead of pdf(), specify resolution\n    tiff(filename = out, units = \"in\", width = 8, height = 6, res = 300)\nprint(\"making level plot or printing now\")\n    p &lt;- levelplot(as.matrix(-log(d)), main = inf, xlab = \"Reference bases\", ylab = \"Read bases\", panel = myPanel, col.regions = colorRampPalette(c(\"white\", \"red\"))(256))\n    \n    print(p)\n    \n    dev.off()\n    \n}"
  }
]